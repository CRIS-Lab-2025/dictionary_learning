{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T20:34:06.850836Z",
     "start_time": "2025-03-13T20:34:06.670822Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from dictionary import AutoEncoder\n",
    "from datasets import load_dataset\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T22:57:07.996732Z",
     "start_time": "2025-03-12T22:57:04.829893Z"
    }
   },
   "source": [
    "# Get 1000 sentences from the pile. \n",
    "\n",
    "# Load The Pile in streaming mode\n",
    "dataset = load_dataset(\"monology/pile-uncopyrighted\", split=\"train\", streaming=True)\n",
    "\n",
    "# Collect 1,000 random sentences\n",
    "random_sentences = []\n",
    "for i, example in enumerate(dataset):\n",
    "    random_sentences.append(example[\"text\"])\n",
    "    if len(random_sentences) >= 100:\n",
    "        break\n",
    "\n",
    "# Save or process sentences\n",
    "with open(\"random_sentences.txt\", \"w\") as f:\n",
    "    for sentence in random_sentences:\n",
    "        f.write(sentence + \"\\n\")\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T20:34:10.722Z",
     "start_time": "2025-03-13T20:34:10.502258Z"
    }
   },
   "source": [
    "# Load the Pythia model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m-deduped\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m-deduped\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T20:34:18.878353Z",
     "start_time": "2025-03-13T20:34:18.874926Z"
    }
   },
   "source": [
    "activation_list = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    \"\"\"Hook function to capture activations from the 4th MLP layer.\"\"\"\n",
    "    activation_list.append(output)\n",
    "\n",
    "# Hook 4th MLP layer (index 3)\n",
    "layer_to_hook = model.gpt_neox.layers[4].mlp\n",
    "hook = layer_to_hook.register_forward_hook(hook_fn)\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T20:34:23.445062Z",
     "start_time": "2025-03-13T20:34:23.436201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read from random_sentences.txt\n",
    "random_sentences = []\n",
    "with open('random_sentences.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if i > 1000:\n",
    "            break\n",
    "        random_sentences.append(line)\n",
    "        \n",
    "print(random_sentences[200])\n",
    "    "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            <description>Immunization Registry Status</description>\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T20:34:25.728495Z",
     "start_time": "2025-03-13T20:34:25.724278Z"
    }
   },
   "cell_type": "code",
   "source": "print(random_sentences[0])",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is done, and submitted. You can play “Survival of the Tastiest” on Android, and on the web. Playing on the web works, but you have to simulate multi-touch for table moving and that can be a bit confusing.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T20:35:02.121471Z",
     "start_time": "2025-03-13T20:34:31.305855Z"
    }
   },
   "source": [
    "# Store per-token activations\n",
    "individual_activations = [] \n",
    "    \n",
    "for i, sentence in enumerate(random_sentences):\n",
    "    input_ids_batch = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    model(**input_ids_batch)  # Forward pass to capture activations\n",
    "\n",
    "    if activation_list:\n",
    "        # We are saving the seq_len, hidden_dim amount of activations. which is cool. \n",
    "        activations = activation_list[-1].squeeze(0)  # Shape: (seq_len, hidden_dim)\n",
    "        individual_activations.append(activations)\n",
    "    activation_list.clear()\n",
    "\n",
    "print(f\"Captured activations for {len(individual_activations)} sentences.\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured activations for 1001 sentences.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T20:35:02.859032Z",
     "start_time": "2025-03-13T20:35:02.165777Z"
    }
   },
   "source": [
    "# Load Dictionary Learning AutoEncoder\n",
    "ae = AutoEncoder.from_pretrained(\n",
    "    \"dictionaries/pythia-70m-deduped/mlp_out_layer4/10_32768/ae.pt\",\n",
    "    # Let torch automatially choose device based on asvail.\n",
    "    # map_location=torch.device('cpu')\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T20:35:14.972009Z",
     "start_time": "2025-03-13T20:35:02.887337Z"
    }
   },
   "source": [
    "# Convert activations to sparse representations\n",
    "sparse_representations = []\n",
    "for activations in individual_activations:\n",
    "    sparse_repr = ae.encode(activations).detach().cpu().numpy()  # (seq_len, dict_size)\n",
    "    sparse_representations.append(sparse_repr)\n",
    "print(f\"Processed {len(sparse_representations)} sentences into token-aligned sparse representations.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1001 sentences into token-aligned sparse representations.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T20:35:15.024539Z",
     "start_time": "2025-03-13T20:35:15.022389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dict_size = len(sparse_representations[0][0]) \n",
    "print(dict_size)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32768\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-13T20:35:15.077421Z"
    }
   },
   "source": [
    "# Aggregate features: Find top activated features across all tokens in all sentences\n",
    "vals = [0 for i in range(dict_size)]\n",
    "num = [0 for i in range(dict_size)]\n",
    "context = [[] for i in range(dict_size)]\n",
    "for i, sentence_features in enumerate(sparse_representations):\n",
    "    for j, token_features in enumerate(sentence_features):\n",
    "        # Can features be negative???\n",
    "        # Does this 800 make sense anymore?\n",
    "        top_indices = np.argsort(token_features)[-2000:][::-1]  # Top 800 features per token\n",
    "        # Aggregate all the features across a sentence. Do set intersection afterwards so that only feature common across all the sentences are considered. We'll also maintain the average value for all the seen features. then, we'll get the decoded output with these valeus. Then, we'll scale those weights alone by 10x. using  this new model, we'll do text generation and see if the feature common across all sentences shows up a lot, which would confirm our hypothesis. \n",
    "        # for idx in top_indices:\n",
    "        #     feature_counts[idx] = feature_counts.get(idx, 0) + 1\n",
    "        # Aggregate features across sentences. \n",
    "        for idx in top_indices:\n",
    "            num[idx] += 1\n",
    "            vals[idx] += token_features[idx]\n",
    "            context[idx].append((i, j))\n",
    "    \n",
    "    \n",
    "            "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T23:09:34.351445Z",
     "start_time": "2025-03-12T23:09:34.346292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the mean vals\n",
    "mean = [val / num if num > 0 else 0 for val, num in zip(vals, num)]\n",
    "print(len(mean))\n",
    "print(mean[:10])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32768\n",
      "[0, 0, 0, 0, np.float32(0.1258342), np.float32(0.14910175), 0, 0, 0, np.float32(0.076006316)]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T23:11:48.451607Z",
     "start_time": "2025-03-12T23:11:48.443758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter: only consider indices that happen more than 5 times. \n",
    "lots_samples = [[idx, num, mean[idx]] for idx, num in enumerate(num) if num > 5]\n",
    "print(len(lots_samples))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9503\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T23:12:02.285905Z",
     "start_time": "2025-03-12T23:12:02.273099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sort mean of those indices.\n",
    "lots_samples.sort(key=lambda x: x[2], reverse=True)\n",
    "print(len(lots_samples))\n",
    "print(lots_samples[:10])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9503\n",
      "[[20383, 2193, np.float32(12.272572)], [18192, 1753, np.float32(5.0215034)], [25721, 110, np.float32(2.8978717)], [22113, 126, np.float32(2.6947615)], [1186, 102, np.float32(2.6079156)], [6122, 27, np.float32(2.577307)], [32061, 28, np.float32(2.443505)], [26654, 1558, np.float32(2.418172)], [25956, 32, np.float32(2.303011)], [6065, 122, np.float32(2.105288)]]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T23:25:44.195825Z",
     "start_time": "2025-03-12T23:25:44.187643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the context for the indices.\n",
    "sig = [(context[idx], idx, num, mean) for idx, num, mean in lots_samples]\n",
    "print(len(sig))\n",
    "print(sig[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9503\n",
      "([(0, 0), (0, 6), (1, 0), (2, 0), (2, 12), (3, 0), (4, 0), (4, 2), (5, 0), (6, 0), (6, 15), (7, 0), (8, 0), (8, 1), (8, 42), (8, 43), (9, 0), (10, 0), (10, 23), (11, 0), (12, 0), (12, 13), (12, 72), (12, 77), (12, 86), (13, 0), (14, 0), (14, 27), (15, 0), (16, 0), (16, 16), (16, 17), (16, 32), (17, 0), (18, 0), (18, 36), (19, 0), (20, 0), (20, 29), (20, 30), (21, 0), (22, 0), (22, 19), (22, 38), (23, 0), (24, 0), (24, 27), (25, 0), (26, 0), (26, 22), (26, 62), (27, 0), (28, 0), (28, 15), (29, 0), (30, 0), (30, 8), (30, 21), (30, 28), (31, 0), (32, 0), (32, 10), (33, 0), (34, 0), (34, 26), (35, 0), (36, 0), (36, 20), (36, 32), (36, 73), (37, 0), (38, 0), (38, 10), (39, 0), (40, 0), (40, 18), (41, 0), (42, 0), (42, 13), (43, 0), (44, 0), (44, 1), (45, 0), (46, 0), (46, 9), (46, 10), (47, 0), (48, 0), (48, 1), (48, 18), (48, 71), (49, 0), (50, 0), (50, 29), (50, 46), (51, 0), (52, 0), (52, 16), (52, 17), (52, 77), (52, 107), (53, 0), (54, 0), (54, 1), (55, 0), (56, 0), (56, 28), (57, 0), (58, 0), (58, 55), (58, 56), (59, 0), (60, 0), (60, 34), (61, 0), (62, 0), (62, 46), (63, 0), (64, 0), (64, 1), (64, 26), (64, 27), (65, 0), (66, 0), (66, 21), (67, 0), (68, 0), (68, 1), (68, 16), (68, 17), (68, 20), (68, 46), (68, 69), (69, 0), (70, 0), (70, 1), (71, 0), (72, 0), (72, 3), (73, 0), (74, 0), (74, 1), (74, 24), (74, 29), (75, 0), (76, 0), (76, 19), (76, 38), (77, 0), (78, 0), (78, 6), (79, 0), (80, 0), (80, 13), (80, 47), (81, 0), (82, 0), (82, 1), (82, 12), (83, 0), (84, 0), (84, 8), (85, 0), (86, 0), (86, 1), (86, 11), (87, 0), (88, 0), (88, 6), (88, 11), (88, 19), (88, 95), (88, 118), (88, 128), (88, 143), (89, 0), (90, 0), (90, 19), (91, 0), (92, 0), (92, 1), (92, 15), (93, 0), (94, 0), (94, 4), (95, 0), (96, 0), (96, 26), (97, 0), (98, 0), (98, 15), (99, 0), (100, 0), (100, 11), (101, 0), (102, 0), (102, 1), (103, 0), (104, 0), (104, 24), (104, 25), (105, 0), (106, 0), (106, 7), (107, 0), (108, 0), (108, 15), (109, 0), (110, 0), (110, 4), (111, 0), (111, 1), (111, 20), (112, 0), (112, 12), (113, 0), (113, 10), (113, 18), (114, 0), (115, 0), (115, 18), (116, 0), (117, 0), (117, 7), (117, 92), (118, 0), (118, 5), (119, 0), (119, 3), (120, 0), (120, 1), (120, 9), (121, 0), (121, 1), (121, 11), (122, 0), (122, 1), (122, 4), (123, 0), (123, 1), (123, 15), (124, 0), (124, 1), (124, 6), (125, 0), (125, 1), (125, 10), (126, 0), (126, 1), (126, 10), (127, 0), (127, 1), (127, 4), (128, 0), (128, 1), (128, 15), (129, 0), (129, 1), (129, 6), (130, 0), (130, 1), (130, 11), (131, 0), (131, 1), (131, 10), (132, 0), (132, 1), (132, 4), (133, 0), (133, 1), (133, 15), (134, 0), (134, 1), (134, 6), (135, 0), (135, 1), (135, 10), (136, 0), (136, 1), (136, 11), (137, 0), (137, 1), (137, 4), (138, 0), (138, 1), (138, 15), (139, 0), (139, 1), (139, 6), (140, 0), (140, 1), (140, 17), (141, 0), (141, 1), (141, 11), (142, 0), (142, 1), (142, 4), (143, 0), (143, 1), (143, 15), (144, 0), (144, 1), (144, 6), (145, 0), (145, 1), (145, 10), (146, 0), (146, 1), (146, 10), (147, 0), (147, 1), (147, 4), (148, 0), (148, 1), (148, 15), (149, 0), (149, 1), (149, 6), (150, 0), (150, 1), (150, 10), (151, 0), (151, 1), (151, 10), (152, 0), (152, 1), (152, 4), (153, 0), (153, 1), (153, 15), (154, 0), (154, 1), (154, 6), (155, 0), (155, 1), (155, 10), (156, 0), (156, 1), (156, 10), (157, 0), (157, 1), (157, 4), (158, 0), (158, 1), (158, 15), (159, 0), (159, 1), (159, 6), (160, 0), (160, 1), (160, 11), (161, 0), (161, 1), (161, 10), (162, 0), (162, 1), (162, 4), (163, 0), (163, 1), (163, 15), (164, 0), (164, 1), (164, 6), (165, 0), (165, 1), (165, 10), (166, 0), (166, 1), (166, 10), (167, 0), (167, 1), (167, 4), (168, 0), (168, 1), (168, 15), (169, 0), (169, 1), (169, 6), (170, 0), (170, 1), (170, 10), (171, 0), (171, 1), (171, 10), (172, 0), (172, 1), (172, 4), (173, 0), (173, 1), (173, 15), (174, 0), (174, 1), (174, 6), (175, 0), (175, 1), (175, 10), (176, 0), (176, 1), (176, 10), (177, 0), (177, 1), (177, 4), (178, 0), (178, 1), (178, 15), (179, 0), (179, 1), (179, 6), (180, 0), (180, 1), (180, 11), (181, 0), (181, 1), (181, 10), (182, 0), (182, 1), (182, 4), (183, 0), (183, 1), (183, 15), (184, 0), (184, 1), (184, 6), (185, 0), (185, 1), (185, 13), (186, 0), (186, 1), (186, 10), (187, 0), (187, 1), (187, 4), (188, 0), (188, 1), (188, 15), (189, 0), (189, 1), (189, 6), (190, 0), (190, 1), (190, 11), (191, 0), (191, 1), (191, 11), (192, 0), (192, 1), (192, 4), (193, 0), (193, 1), (193, 15), (194, 0), (194, 1), (194, 6), (195, 0), (195, 1), (195, 12), (196, 0), (196, 1), (196, 10), (197, 0), (197, 1), (197, 4), (198, 0), (198, 1), (198, 15), (199, 0), (199, 1), (199, 6), (200, 0), (200, 1), (200, 11), (201, 0), (201, 1), (201, 10), (202, 0), (202, 1), (202, 4), (203, 0), (203, 1), (203, 15), (204, 0), (204, 1), (204, 6), (205, 0), (205, 1), (205, 13), (206, 0), (206, 1), (206, 10), (207, 0), (207, 1), (207, 4), (208, 0), (208, 1), (208, 15), (209, 0), (209, 1), (209, 6), (210, 0), (210, 1), (210, 12), (211, 0), (211, 1), (211, 10), (212, 0), (212, 1), (212, 4), (213, 0), (213, 1), (213, 15), (214, 0), (214, 1), (214, 6), (215, 0), (215, 1), (215, 9), (216, 0), (216, 1), (216, 10), (217, 0), (217, 1), (217, 4), (218, 0), (218, 1), (218, 15), (219, 0), (219, 1), (219, 6), (220, 0), (220, 1), (220, 11), (221, 0), (221, 1), (221, 10), (222, 0), (222, 1), (222, 4), (223, 0), (223, 1), (223, 15), (224, 0), (224, 1), (224, 6), (225, 0), (225, 1), (225, 9), (226, 0), (226, 1), (226, 10), (227, 0), (227, 1), (227, 4), (228, 0), (228, 1), (228, 4), (229, 0), (229, 3), (230, 0), (231, 0), (231, 6), (232, 0), (233, 0), (233, 11), (233, 17), (234, 0), (234, 8), (235, 0), (236, 0), (236, 47), (236, 82), (237, 0), (238, 0), (238, 8), (239, 0), (240, 0), (240, 18), (241, 0), (242, 0), (242, 24), (243, 0), (244, 0), (244, 8), (244, 13), (245, 0), (246, 0), (246, 1), (246, 18), (246, 55), (247, 0), (248, 0), (248, 1), (248, 2), (248, 3), (248, 4), (249, 0), (250, 0), (250, 1), (250, 4), (251, 0), (252, 0), (252, 5), (252, 49), (253, 0), (254, 0), (254, 11), (254, 21), (254, 57), (255, 0), (255, 2), (256, 0), (257, 0), (257, 13), (258, 0), (259, 0), (259, 56), (260, 0), (260, 34), (261, 0), (261, 14), (261, 39), (262, 0), (262, 15), (262, 37), (262, 48), (262, 53), (262, 62), (263, 0), (263, 9), (264, 0), (265, 0), (265, 2), (266, 0), (267, 0), (267, 5), (268, 0), (268, 19), (269, 0), (270, 0), (270, 10), (270, 16), (271, 0), (271, 9), (271, 14), (271, 17), (272, 0), (273, 0), (273, 15), (273, 17), (273, 25), (274, 0), (274, 2), (274, 5), (274, 11), (274, 51), (275, 0), (275, 1), (275, 5), (276, 0), (277, 0), (277, 36), (278, 0), (278, 15), (278, 36), (279, 0), (280, 0), (281, 0), (281, 1), (281, 13), (282, 0), (283, 0), (283, 25), (283, 44), (283, 81), (284, 0), (285, 0), (285, 22), (286, 0), (287, 0), (287, 43), (287, 44), (288, 0), (289, 0), (289, 35), (290, 0), (291, 0), (291, 18), (292, 0), (293, 0), (293, 36), (294, 0), (295, 0), (295, 36), (295, 37), (296, 0), (297, 0), (297, 4), (298, 0), (298, 31), (299, 0), (299, 13), (300, 0), (300, 35), (301, 0), (301, 2), (301, 18), (302, 0), (302, 6), (302, 22), (303, 0), (303, 14), (304, 0), (305, 0), (305, 5), (306, 0), (306, 19), (307, 0), (307, 1), (307, 33), (308, 0), (308, 1), (308, 3), (308, 17), (309, 0), (309, 6), (309, 11), (310, 0), (310, 19), (311, 0), (312, 0), (312, 41), (312, 72), (313, 0), (314, 0), (314, 23), (315, 0), (315, 2), (316, 0), (317, 0), (317, 12), (318, 0), (319, 0), (319, 55), (320, 0), (320, 34), (321, 0), (321, 27), (321, 38), (322, 0), (322, 1), (323, 0), (324, 0), (324, 2), (325, 0), (326, 0), (326, 23), (327, 0), (328, 0), (329, 0), (329, 1), (329, 4), (329, 14), (329, 26), (330, 0), (331, 0), (331, 1), (331, 4), (332, 0), (333, 0), (333, 6), (334, 0), (335, 0), (335, 11), (336, 0), (337, 0), (337, 15), (338, 0), (339, 0), (339, 17), (339, 20), (339, 58), (339, 78), (340, 0), (341, 0), (341, 9), (341, 20), (342, 0), (342, 2), (343, 0), (344, 0), (344, 18), (345, 0), (346, 0), (346, 9), (347, 0), (347, 5), (348, 0), (348, 6), (349, 0), (349, 1), (349, 6), (350, 0), (350, 3), (351, 0), (352, 0), (352, 22), (352, 56), (353, 0), (353, 1), (353, 16), (354, 0), (355, 0), (355, 2), (355, 17), (356, 0), (356, 1), (356, 13), (357, 0), (358, 0), (358, 2), (359, 0), (360, 0), (360, 1), (360, 3), (360, 4), (360, 5), (360, 9), (360, 10), (361, 0), (361, 14), (362, 0), (363, 0), (363, 2), (364, 0), (365, 0), (365, 14), (366, 0), (366, 23), (367, 0), (368, 0), (369, 0), (369, 2), (369, 7), (369, 8), (370, 0), (371, 0), (371, 19), (371, 45), (372, 0), (373, 0), (373, 28), (374, 0), (375, 0), (375, 23), (376, 0), (377, 0), (377, 18), (378, 0), (379, 0), (379, 2), (380, 0), (381, 0), (381, 4), (382, 0), (382, 28), (382, 48), (383, 0), (384, 0), (384, 2), (385, 0), (385, 2), (385, 21), (386, 0), (386, 5), (387, 0), (387, 32), (388, 0), (389, 0), (389, 4), (390, 0), (390, 4), (391, 0), (391, 1), (391, 7), (392, 0), (393, 0), (393, 1), (394, 0), (395, 0), (395, 2), (396, 0), (396, 10), (397, 0), (397, 8), (398, 0), (398, 11), (399, 0), (400, 0), (400, 7), (401, 0), (401, 9), (402, 0), (402, 7), (403, 0), (403, 6), (404, 0), (404, 1), (405, 0), (405, 8), (406, 0), (406, 8), (407, 0), (407, 5), (408, 0), (408, 1), (408, 11), (409, 0), (409, 1), (409, 5), (410, 0), (410, 1), (410, 10), (411, 0), (411, 1), (411, 9), (412, 0), (412, 1), (412, 7), (413, 0), (413, 2), (414, 0), (414, 1), (415, 0), (415, 1), (415, 17), (416, 0), (416, 27), (416, 52), (416, 55), (416, 96), (416, 113), (416, 141), (416, 150), (416, 274), (417, 0), (417, 2), (418, 0), (419, 0), (419, 1), (419, 4), (419, 26), (420, 0), (421, 0), (421, 19), (421, 30), (421, 73), (421, 80), (421, 90), (421, 94), (421, 116), (422, 0), (422, 5), (423, 0), (423, 7), (424, 0), (424, 2), (425, 0), (425, 1), (426, 0), (427, 0), (427, 3), (428, 0), (428, 1), (429, 0), (429, 1), (430, 0), (430, 1), (431, 0), (431, 1), (432, 0), (432, 1), (433, 0), (433, 1), (434, 0), (434, 1), (435, 0), (435, 1), (436, 0), (436, 1), (437, 0), (437, 1), (438, 0), (439, 0), (439, 2), (440, 0), (441, 0), (441, 9), (441, 75), (441, 124), (442, 0), (442, 1), (442, 89), (442, 90), (443, 0), (443, 1), (443, 4), (444, 0), (444, 5), (445, 0), (445, 7), (446, 0), (446, 2), (446, 12), (447, 0), (447, 10), (448, 0), (448, 1), (449, 0), (450, 0), (450, 45), (450, 60), (451, 0), (451, 1), (451, 7), (452, 0), (453, 0), (453, 1), (453, 2), (453, 5), (454, 0), (454, 10), (455, 0), (455, 10), (456, 0), (456, 10), (457, 0), (457, 1), (458, 0), (458, 10), (459, 0), (459, 31), (460, 0), (461, 0), (461, 1), (461, 3), (461, 40), (462, 0), (463, 0), (463, 5), (464, 0), (464, 7), (465, 0), (465, 3), (466, 0), (466, 2), (467, 0), (467, 1), (468, 0), (469, 0), (470, 0), (471, 0), (471, 1), (472, 0), (473, 0), (473, 1), (474, 0), (475, 0), (475, 17), (475, 52), (475, 65), (476, 0), (477, 0), (477, 32), (477, 33), (478, 0), (478, 8), (479, 0), (479, 6), (479, 32), (479, 116), (480, 0), (480, 15), (480, 16), (480, 124), (480, 125), (480, 129), (481, 0), (481, 21), (481, 25), (481, 56), (481, 125), (481, 182), (482, 0), (482, 9), (483, 0), (484, 0), (484, 2), (484, 14), (484, 57), (485, 0), (486, 0), (486, 11), (487, 0), (488, 0), (488, 1), (488, 2), (488, 3), (488, 19), (488, 22), (489, 0), (490, 0), (490, 2), (490, 35), (491, 0), (492, 0), (492, 19), (492, 26), (493, 0), (494, 0), (494, 11), (495, 0), (496, 0), (496, 5), (496, 67), (497, 0), (498, 0), (498, 12), (498, 43), (499, 0), (500, 0), (500, 30), (501, 0), (502, 0), (502, 46), (503, 0), (504, 0), (504, 11), (505, 0), (506, 0), (506, 30), (506, 33), (507, 0), (508, 0), (508, 1), (508, 2), (508, 3), (508, 9), (508, 27), (508, 71), (509, 0), (510, 0), (510, 1), (510, 16), (511, 0), (512, 0), (512, 3), (513, 0), (514, 0), (514, 12), (515, 0), (516, 0), (516, 16), (516, 82), (516, 117), (517, 0), (518, 0), (518, 24), (519, 0), (520, 0), (520, 47), (521, 0), (522, 0), (522, 3), (523, 0), (524, 0), (524, 17), (525, 0), (526, 0), (526, 30), (527, 0), (528, 0), (528, 11), (529, 0), (530, 0), (530, 1), (530, 16), (531, 0), (532, 0), (532, 1), (532, 35), (532, 50), (533, 0), (534, 0), (534, 5), (535, 0), (536, 0), (536, 16), (537, 0), (538, 0), (538, 3), (539, 0), (540, 0), (540, 45), (541, 0), (542, 0), (542, 5), (543, 0), (544, 0), (544, 47), (545, 0), (546, 0), (546, 10), (546, 13), (546, 75), (547, 0), (547, 9), (548, 0), (548, 35), (549, 0), (549, 25), (550, 0), (550, 19), (550, 21), (550, 255), (551, 0), (551, 68), (552, 0), (553, 0), (553, 16), (554, 0), (554, 32), (555, 0), (556, 0), (556, 30), (557, 0), (558, 0), (558, 56), (559, 0), (559, 7), (560, 0), (561, 0), (561, 9), (562, 0), (563, 0), (563, 17), (564, 0), (565, 2), (566, 0), (567, 0), (567, 24), (567, 29), (567, 45), (567, 48), (567, 67), (567, 82), (567, 85), (567, 97), (568, 0), (569, 0), (569, 12), (570, 0), (570, 15), (571, 0), (572, 0), (572, 14), (572, 28), (573, 0), (574, 0), (574, 18), (575, 0), (576, 0), (576, 17), (577, 0), (578, 0), (578, 7), (579, 0), (580, 2), (581, 0), (582, 0), (582, 47), (582, 60), (583, 0), (584, 2), (585, 0), (586, 0), (586, 69), (587, 0), (588, 0), (588, 12), (589, 0), (589, 6), (589, 8), (590, 0), (591, 0), (591, 8), (592, 0), (592, 1), (592, 2), (592, 3), (592, 15), (593, 0), (593, 13), (594, 0), (595, 0), (595, 1), (595, 11), (596, 0), (596, 17), (597, 0), (598, 0), (598, 1), (598, 12), (599, 0), (600, 0), (600, 1), (600, 31), (601, 0), (602, 0), (602, 33), (603, 0), (604, 2), (605, 0), (606, 0), (606, 55), (607, 0), (608, 0), (608, 27), (609, 0), (610, 2), (611, 0), (612, 0), (612, 4), (612, 5), (612, 18), (612, 19), (612, 35), (612, 39), (613, 0), (614, 0), (614, 1), (614, 2), (614, 25), (615, 0), (616, 0), (616, 1), (616, 5), (616, 6), (616, 62), (617, 0), (618, 2), (619, 0), (620, 0), (620, 1), (620, 11), (620, 27), (621, 0), (622, 0), (622, 27), (623, 0), (624, 0), (624, 4), (625, 0), (625, 1), (625, 5), (626, 0), (626, 7), (627, 0), (627, 1), (627, 3), (627, 7), (628, 0), (629, 0), (629, 1), (629, 2), (630, 0), (631, 0), (631, 1), (631, 2), (631, 25), (632, 0), (633, 0), (633, 1), (633, 2), (633, 7), (634, 0), (635, 0), (635, 1), (635, 11), (636, 0), (637, 0), (637, 1), (637, 2), (637, 3), (637, 12), (638, 0), (639, 0), (639, 5), (640, 0), (641, 0), (641, 12), (642, 0), (643, 0), (643, 18), (644, 0), (644, 1), (644, 5), (644, 17), (644, 18), (645, 0), (645, 8), (645, 31), (646, 0), (647, 0), (647, 9), (648, 0), (649, 0), (649, 17), (650, 0), (651, 0), (651, 10), (651, 13), (651, 35), (651, 104), (652, 0), (653, 0), (653, 17), (653, 18), (653, 105), (653, 107), (654, 0), (655, 0), (655, 1), (655, 16), (656, 0), (657, 0), (657, 11), (658, 0), (658, 1), (658, 3), (658, 10), (659, 0), (659, 4), (660, 0), (660, 11), (661, 0), (661, 1), (661, 2), (661, 6), (661, 11), (662, 0), (662, 14), (663, 0), (663, 1), (663, 13), (664, 0), (664, 1), (664, 19), (665, 0), (665, 12), (666, 0), (666, 15), (667, 0), (667, 13), (668, 0), (668, 11), (669, 0), (669, 8), (669, 9), (669, 22), (670, 0), (671, 0), (671, 13), (672, 0), (672, 1), (672, 7), (673, 0), (673, 12), (674, 0), (674, 8), (675, 0), (675, 20), (676, 0), (676, 11), (677, 0), (677, 1), (677, 10), (678, 0), (678, 10), (679, 0), (679, 10), (680, 0), (680, 13), (681, 0), (681, 22), (682, 0), (683, 0), (683, 14), (684, 0), (684, 1), (684, 41), (685, 0), (685, 1), (685, 17), (686, 0), (686, 9), (687, 0), (687, 2), (687, 12), (688, 0), (688, 6), (688, 12), (689, 0), (689, 3), (689, 5), (689, 12), (690, 0), (690, 5), (691, 0), (691, 13), (691, 38), (692, 0), (693, 0), (693, 10), (694, 0), (694, 5), (694, 7), (695, 0), (695, 12), (696, 0), (696, 1), (696, 4), (696, 5), (697, 0), (697, 1), (697, 17), (698, 0), (698, 19), (698, 24), (699, 0), (700, 0), (700, 19), (701, 0), (702, 0), (702, 17), (703, 0), (704, 0), (704, 23), (704, 24), (704, 85), (704, 86), (704, 143), (705, 0), (706, 0), (706, 1), (707, 0), (708, 0), (708, 1), (708, 13), (708, 50), (709, 0), (710, 2), (711, 0), (712, 0), (712, 48), (713, 0), (713, 31), (714, 0), (714, 14), (714, 16), (714, 33), (714, 45), (715, 0), (716, 0), (716, 1), (716, 24), (716, 52), (716, 60), (717, 0), (717, 29), (718, 0), (718, 4), (718, 5), (719, 0), (720, 0), (720, 37), (721, 0), (722, 0), (722, 17), (723, 0), (724, 0), (724, 21), (725, 0), (725, 7), (726, 0), (726, 1), (726, 13), (727, 0), (727, 1), (727, 5), (728, 0), (728, 1), (728, 15), (729, 0), (730, 0), (730, 1), (730, 23), (731, 0), (732, 0), (732, 1), (732, 2), (732, 3), (732, 4), (732, 48), (733, 0), (734, 0), (734, 17), (734, 40), (734, 53), (735, 0), (736, 0), (736, 3), (737, 0), (737, 9), (737, 16), (737, 27), (737, 28), (738, 0), (739, 0), (739, 14), (740, 0), (740, 12), (741, 0), (742, 0), (742, 11), (742, 12), (743, 0), (743, 3), (744, 0), (744, 18), (745, 0), (746, 0), (746, 16), (746, 17), (747, 0), (747, 7), (748, 0), (748, 18), (748, 19), (749, 0), (750, 0), (750, 42), (751, 0), (752, 0), (752, 17), (753, 0), (754, 2), (755, 0), (756, 0), (756, 21), (756, 22), (756, 104), (757, 0), (758, 0), (758, 2), (758, 3), (758, 8), (758, 23), (758, 27), (758, 72), (758, 80), (758, 82), (758, 142), (758, 168), (758, 186), (758, 187), (758, 208), (759, 0), (759, 1), (759, 2), (760, 0), (761, 0), (761, 26), (762, 0), (763, 0), (763, 11), (764, 0), (765, 0), (765, 29), (766, 0), (767, 0), (767, 1), (767, 26), (767, 49), (768, 0), (769, 0), (769, 54), (770, 0), (770, 1), (770, 14), (771, 0), (772, 0), (772, 53), (773, 0), (774, 0), (774, 57), (775, 0), (775, 13), (776, 0), (777, 2), (778, 0), (779, 0), (779, 16), (779, 18), (779, 66), (779, 75), (779, 76), (780, 0), (781, 0), (781, 1), (781, 14), (781, 53), (782, 0), (782, 4), (783, 0), (784, 0), (784, 4), (785, 0), (786, 0), (786, 3), (786, 34), (786, 35), (787, 0), (788, 0), (788, 15), (788, 29), (788, 34), (789, 0), (790, 0), (790, 28), (791, 0), (791, 2), (792, 0), (793, 0), (793, 4), (793, 6), (793, 8), (794, 0), (795, 0), (795, 29), (796, 0), (796, 4), (797, 0), (797, 1), (797, 9), (798, 0), (798, 3), (798, 6), (799, 0), (799, 8), (800, 0), (800, 3), (801, 0), (801, 8), (801, 9), (802, 0), (802, 7), (802, 8), (803, 0), (803, 9), (804, 0), (805, 0), (805, 1), (805, 10), (806, 0), (806, 7), (807, 0), (807, 3), (807, 6), (807, 7), (808, 0), (808, 2), (808, 3), (809, 0), (809, 1), (810, 0), (811, 0), (811, 1), (811, 9), (812, 0), (813, 0), (813, 2), (814, 0), (815, 0), (815, 11), (816, 0), (816, 1), (816, 9), (817, 0), (817, 3), (817, 6), (818, 0), (818, 8), (819, 0), (819, 3), (820, 0), (820, 8), (820, 9), (821, 0), (821, 7), (821, 8), (822, 0), (822, 10), (823, 0), (824, 0), (825, 0), (825, 1), (825, 30), (826, 0), (826, 51), (826, 143), (826, 184), (827, 0), (827, 5), (828, 0), (829, 0), (829, 17), (830, 0), (831, 0), (831, 32), (832, 0), (833, 0), (833, 3), (833, 6), (834, 0), (835, 0), (835, 1), (836, 0), (837, 0), (837, 2), (838, 0), (839, 0), (839, 5), (840, 0), (841, 0), (841, 11), (841, 17), (841, 85), (842, 0), (842, 18), (842, 19), (842, 52), (843, 0), (844, 0), (844, 17), (845, 0), (846, 0), (846, 30), (847, 0), (848, 0), (848, 7), (848, 11), (848, 100), (849, 0), (850, 0), (850, 6), (850, 18), (850, 19), (850, 36), (850, 67), (851, 0), (852, 0), (852, 23), (852, 24), (852, 34), (853, 0), (854, 0), (854, 16), (854, 33), (854, 38), (855, 0), (856, 0), (856, 21), (856, 22), (856, 56), (856, 76), (856, 82), (857, 0), (858, 0), (858, 1), (858, 9), (858, 30), (858, 31), (858, 36), (859, 0), (860, 0), (860, 10), (860, 65), (861, 0), (862, 0), (862, 18), (862, 81), (862, 89), (863, 0), (864, 0), (864, 21), (864, 22), (864, 23), (864, 72), (865, 0), (866, 0), (866, 43), (866, 88), (866, 99), (866, 129), (867, 0), (868, 0), (868, 10), (868, 33), (868, 89), (868, 126), (868, 128), (869, 0), (870, 0), (870, 21), (870, 54), (870, 59), (870, 63), (870, 74), (870, 103), (870, 121), (870, 124), (870, 157), (870, 165), (871, 0), (872, 0), (872, 36), (873, 0), (874, 0), (874, 8), (874, 11), (874, 15), (874, 30), (875, 0), (876, 0), (876, 20), (876, 21), (877, 0), (878, 0), (878, 17), (878, 18), (878, 19), (878, 21), (879, 0), (880, 0), (880, 22), (880, 23), (881, 0), (882, 0), (882, 2), (882, 5), (882, 6), (883, 0), (884, 0), (884, 2), (885, 0), (886, 0), (886, 12), (887, 0), (888, 0), (888, 2), (889, 0), (890, 0), (890, 5), (891, 0), (892, 0), (892, 17), (893, 0), (894, 0), (894, 1), (894, 2), (895, 0), (896, 0), (896, 3), (896, 4), (896, 6), (896, 13), (896, 16), (897, 0), (898, 0), (898, 29), (898, 31), (899, 0), (900, 0), (900, 1), (900, 28), (901, 0), (902, 0), (902, 30), (902, 59), (903, 0), (904, 0), (904, 14), (905, 0), (905, 2), (905, 12), (906, 0), (906, 1), (906, 18), (907, 0), (907, 25), (907, 29), (908, 0), (908, 8), (908, 10), (908, 30), (908, 66), (909, 0), (909, 2), (910, 0), (911, 0), (911, 11), (912, 0), (913, 0), (913, 11), (914, 0), (914, 13), (914, 14), (914, 25), (915, 0), (915, 4), (916, 0), (916, 5), (917, 0), (917, 5), (918, 0), (918, 2), (919, 0), (919, 8), (920, 0), (920, 8), (921, 0), (921, 8), (922, 0), (922, 2), (922, 10), (923, 0), (923, 2), (923, 10), (924, 0), (924, 10), (925, 0), (925, 5), (926, 0), (927, 0), (927, 2), (928, 0), (928, 11), (929, 0), (929, 10), (930, 0), (930, 10), (931, 0), (931, 11), (932, 0), (932, 11), (933, 0), (933, 11), (934, 0), (934, 14), (935, 0), (935, 14), (936, 0), (936, 14), (937, 0), (937, 14), (938, 0), (939, 0), (939, 2), (940, 0), (940, 10), (941, 0), (941, 11), (942, 0), (942, 11), (943, 0), (943, 11), (944, 0), (944, 11), (945, 0), (945, 11), (946, 0), (946, 9), (947, 0), (947, 12), (948, 0), (948, 9), (949, 0), (949, 14), (950, 0), (950, 14), (951, 0), (951, 19), (952, 0), (953, 0), (953, 2), (954, 0), (954, 11), (955, 0), (955, 10), (956, 0), (956, 11), (957, 0), (957, 11), (958, 0), (958, 11), (959, 0), (959, 11), (960, 0), (960, 10), (961, 0), (961, 8), (962, 0), (962, 12), (963, 0), (963, 9), (964, 0), (964, 14), (965, 0), (965, 14), (966, 0), (966, 19), (967, 0), (968, 0), (968, 2), (969, 0), (970, 0), (970, 10), (971, 0), (971, 3), (972, 0), (973, 0), (973, 2), (974, 0), (975, 0), (975, 5), (976, 0), (977, 0), (977, 6), (978, 0), (979, 0), (979, 1), (979, 2), (979, 4), (980, 0), (980, 21), (981, 0), (981, 1), (981, 26), (982, 0), (983, 0), (984, 0), (984, 19), (984, 20), (985, 0), (986, 0), (986, 24), (986, 25), (987, 0), (988, 0), (988, 18), (988, 39), (989, 0), (990, 0), (990, 2), (991, 0), (992, 0), (992, 1), (993, 0), (994, 0), (994, 1), (995, 0), (995, 1), (995, 2), (996, 0), (997, 0), (997, 1), (997, 18), (997, 19), (998, 0), (998, 2), (999, 0), (1000, 0), (1000, 6)], 20383, 2193, np.float32(12.272572))\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T23:29:36.655388Z",
     "start_time": "2025-03-12T23:29:36.640720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Leets sort by len of the sig. Secondary key will be the mean value. \n",
    "sig = sorted(sig, key = lambda x: (len(x[0]), -x[3]))"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T23:37:59.022923Z",
     "start_time": "2025-03-12T23:37:54.965384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter for only stuff where mean > 1.5\n",
    "sig = [x for x in sig if x[3] > 1.5]\n",
    "print(len(sig))\n",
    "print(sig[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "([(111, 3), (275, 20), (329, 6), (382, 142), (582, 19), (582, 21)], 21821, 6, np.float32(2.0713027))\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T23:44:13.438825Z",
     "start_time": "2025-03-12T23:44:13.433392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context, idx, num, mean = sig[0]\n",
    "print(len(context))\n",
    "print(idx)\n",
    "print(mean)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "29401\n",
      "1.6737142\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T23:44:15.267711Z",
     "start_time": "2025-03-12T23:44:15.251860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print those tokens out. \n",
    "\n",
    "for i, j in context:# Tokenize the sentece. \n",
    "    # Print the j'th token\n",
    "    print(i, j) \n",
    "    print(random_sentences[i])\n",
    "    tokenized_sentence = tokenizer(random_sentences[i])['input_ids']\n",
    "    #j'th token\n",
    "    print(tokenizer.convert_ids_to_tokens(tokenized_sentence[j]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 38\n",
      "It is done, and submitted. You can play “Survival of the Tastiest” on Android, and on the web. Playing on the web works, but you have to simulate multi-touch for table moving and that can be a bit confusing.\n",
      "\n",
      "Ġmulti\n",
      "26 6\n",
      "Conversations with my inspiring co-worker Roushey (who also created the “Mechanical Underdogs” signature logo for my intros) further matured the concept, as it involved into the idea of having individual pieces of pasta flying around and trying to evolve until they became all-powerful. A secondary idea here was that the game would work to explain how the Flying Spaghetti Monster came to exist – by evolving from a normal dinner table.\n",
      "\n",
      "Ġco\n",
      "30 44\n",
      "Your plate can spawn little pieces of pasta. You do so by “ordering” them through a menu. Some pastas are better than others; some are faster, some are stronger. They have varying costs, which are debited from your credits (you start with a number of credits).\n",
      "\n",
      "Ġdeb\n",
      "82 1\n",
      "Other non-obvious features had to be dropped, too. For example, when ordering some pasta, you were supposed to select what kind of sauce you’d like with your pasta, each with different attributes. Bolognese, for example, is very strong, but inaccurate; Pesto is very accurate and has great range, but it’s weaker; and my favorite, Vodka, would triggers 10% loss of speed on the pasta hit by it.\n",
      "\n",
      "Ġnon\n",
      "82 2\n",
      "Other non-obvious features had to be dropped, too. For example, when ordering some pasta, you were supposed to select what kind of sauce you’d like with your pasta, each with different attributes. Bolognese, for example, is very strong, but inaccurate; Pesto is very accurate and has great range, but it’s weaker; and my favorite, Vodka, would triggers 10% loss of speed on the pasta hit by it.\n",
      "\n",
      "-\n",
      "88 50\n",
      "Actual programming also took a toll in the development time. Having been programming for a while, I like to believe I got to a point where I know how to make things right, but at the expense of forgetting how to do things wrong in a seemingly good way. What I mean is that I had to take a lot of shortcuts in my code to save time (e.g. a lot of singletons references for cross-communication rather than events or observers, all-encompassing check loops, not fast enough) that left a very sour taste in my mouth. While I know I used to do those a few years ago and survive, I almost cannot accept the state my code is in right now.\n",
      "\n",
      "Ġseemingly\n",
      "261 28\n",
      "And secondly, how is it that he is then speaking to Aberforth in Halfblood Prince? (assuming the ban was for something rather unforgivable, 20 years is a long time?) \n",
      "\n",
      "Ġunfor\n",
      "371 7\n",
      "In 1999, the Major League Baseball All-Century Team was chosen by popular vote of fans. To select the team, a panel of experts first compiled a list of the 100 greatest Major League Baseball players from the past century. Over two million fans then voted on the players using paper and online ballots.\n",
      "\n",
      "ĠAll\n",
      "373 76\n",
      "The top two vote-getters from each position, except outfielders (nine), and the top six pitchers were placed on the team. A select panel then added five legends to create a thirty-man team:—Warren Spahn (who finished #10 among pitchers), Christy Mathewson (#14 among pitchers), Lefty Grove (#18 among pitchers), Honus Wagner (#4 among shortstops), and Stan Musial (#11 among outfielders).\n",
      "\n",
      "ĠHon\n",
      "375 5\n",
      "The nominees for the All-Century team were presented at the 1999 All-Star Game at Fenway Park. Preceding Game 2 of the 1999 World Series, the members of the All-Century Team were revealed. Every living player named to the team attended.\n",
      "\n",
      "ĠAll\n",
      "382 8\n",
      "There was controversy over the inclusion in the All-Century Team of Pete Rose, who had been banned from baseball for life 10 years earlier. Some questioned Rose's presence on a team officially endorsed by Major League Baseball, but fans at the stadium gave him a standing ovation. During the on-field ceremony, which was emceed by Hall of Fame broadcaster Vin Scully, NBC Sports' Jim Gray questioned Rose about his refusal to admit to gambling on baseball.  Gray's interview became controversial, with some arguing that it was good journalism, while others objected that the occasion was an inappropriate setting for Gray's persistence.  After initially refusing to do so, Gray apologized a few days later.  On January 8, 2004, more than four years later, Rose admitted publicly to betting on baseball games in his autobiography My Prison Without Bars.\n",
      "\n",
      "ĠAll\n",
      "416 283\n",
      "Cardiovascular disease (CVD) currently claims nearly one million lives yearly in the US, accounting for nearly 40% of all deaths. Coronary artery disease (CAD) accounts for the largest number of these deaths. While efforts aimed at treating CAD in recent decades have concentrated on surgical and catheter-based interventions, limited resources have been directed toward prevention and rehabilitation. CAD is commonly treated using percutaneous coronary intervention (PCI), and this treatment has increased exponentially since its adoption over three decades ago. Recent questions have been raised regarding the cost-effectiveness of PCI, the extent to which PCI is overused, and whether selected patients may benefit from optimal medical therapy in lieu of PCI. One alternative therapy that has been shown to improve outcomes in CAD is exercise therapy; exercise programs have been shown to have numerous physiological benefits, and a growing number of studies have demonstrated reductions in mortality. Given the high volume of PCI, its high cost, its lack of effect on survival and the potential for alternative treatments including exercise, the current study is termed \"PCI Alternative Using Sustained Exercise\" (PAUSE). The primary aim of PAUSE is to determine whether patients randomized to exercise and lifestyle intervention have greater improvement in coronary function and anatomy compared to those randomized to PCI. Coronary function and anatomy is determined using positron emission tomography combined with computed tomographic angiography (PET/CTA). Our objective is to demonstrate the utility of a non-invasive technology to document the efficacy of exercise as an alternative treatment strategy to PCI.\n",
      "\n",
      "Ġnon\n",
      "516 95\n",
      "The problem is that a huge amount of meaning is lost in the mapping to SQL. SQL is practically (though not theoretically) limited to representing physical models. These are almost always very different from the conceptual model, as many relationships have been condensed (absorbed) into attribute/column relationships, so the semantics of the original relationship are lost. In the process, nullable columns are usually introduced, which adds further to the confusion, as such things cannot easily be correctly constrained (uniqueness, etc) in SQL. So by reverse engineering from the relational form, you're losing most of the benefit of building a conceptual model from the start\n",
      "\n",
      "un\n",
      "518 156\n",
      "This may be hard to see for someone used to O-O modeling, and who's authored an O/RM tool. The problem is that O-O suffers from many of the same problems of loss of semantics. The apparently clear notion of \"attribute\" breaks down when you look at it closely. O-O, although ostensibly behaviour-oriented, introduces attributes to store state, and this attribute orientation is the source of the problem in both cases. Fact-oriented model does not use attributes. Although it may seem obvious that, for example, my surname is an attribute of myself, if the system being modeled accrues the requirement to model families, suddenly surname becomes an attribute of family, and family becomes my attribute. This kind of instability is responsible for much of the rework that's required in evolving legacy systems, as well as many of the mistakes made when they were first modeled. If you want a further example of this loss of semantics, look at my Insurance example, and ask yourself why the VehicleIncident table has a DrivingBloodTestResult column. In fact, if VehicleIncident wasn't explicitly mapped separately, its fields would be in the Claim table.\n",
      "\n",
      "Ġre\n",
      "518 231\n",
      "This may be hard to see for someone used to O-O modeling, and who's authored an O/RM tool. The problem is that O-O suffers from many of the same problems of loss of semantics. The apparently clear notion of \"attribute\" breaks down when you look at it closely. O-O, although ostensibly behaviour-oriented, introduces attributes to store state, and this attribute orientation is the source of the problem in both cases. Fact-oriented model does not use attributes. Although it may seem obvious that, for example, my surname is an attribute of myself, if the system being modeled accrues the requirement to model families, suddenly surname becomes an attribute of family, and family becomes my attribute. This kind of instability is responsible for much of the rework that's required in evolving legacy systems, as well as many of the mistakes made when they were first modeled. If you want a further example of this loss of semantics, look at my Insurance example, and ask yourself why the VehicleIncident table has a DrivingBloodTestResult column. In fact, if VehicleIncident wasn't explicitly mapped separately, its fields would be in the Claim table.\n",
      "\n",
      "Ġwould\n",
      "558 23\n",
      "So by weakly measuring certain aspects of living neurons, it is possible to superbroadcast/ teleport the wavefunction non-classically to the memristors vacancies, correlating each memristor with its neuron statistical ensemble counterpart, sharing the quantum state of the resting potential.\n",
      "\n",
      "Ġnon\n",
      "569 9\n",
      "and the no-cloning theorem is about pure states..\n",
      "\n",
      "Ġpure\n",
      "572 1\n",
      "The no-cloning theorem is normally stated and proven for pure states; the no-broadcast theorem generalizes this result to mixed states.\n",
      "\n",
      "Ġno\n",
      "572 12\n",
      "The no-cloning theorem is normally stated and proven for pure states; the no-broadcast theorem generalizes this result to mixed states.\n",
      "\n",
      "Ġpure\n",
      "574 15\n",
      "And thats why PHASE works for quantum metrology and its ability to harness non classical states\n",
      "\n",
      "Ġnon\n",
      "596 12\n",
      "which is part of Quantum Metrology and its ability to harness non-classical states..\n",
      "\n",
      "Ġnon\n",
      "598 7\n",
      "and all of this can teleport non-classical light..\n",
      "\n",
      "Ġnon\n",
      "620 38\n",
      "The quantum computer may be physically implemented in arbitrary ways but the common apparatus considered to date features a Mach–Zehnder interferometer. The quantum computer is set in a superposition of \"not running\" and \"running\" states by means such as the Quantum Zeno Effect. Those state histories are quantum interfered. After many repetitions of very rapid projective measurements, the \"not running\" state evolves to a final value imprinted into the properties of the quantum computer. Measuring that value allows for learning the result of some types of computations such as Grover's algorithm even though the result was derived from the non-running state of the quantum computer.\n",
      "\n",
      "not\n",
      "620 75\n",
      "The quantum computer may be physically implemented in arbitrary ways but the common apparatus considered to date features a Mach–Zehnder interferometer. The quantum computer is set in a superposition of \"not running\" and \"running\" states by means such as the Quantum Zeno Effect. Those state histories are quantum interfered. After many repetitions of very rapid projective measurements, the \"not running\" state evolves to a final value imprinted into the properties of the quantum computer. Measuring that value allows for learning the result of some types of computations such as Grover's algorithm even though the result was derived from the non-running state of the quantum computer.\n",
      "\n",
      "not\n",
      "620 123\n",
      "The quantum computer may be physically implemented in arbitrary ways but the common apparatus considered to date features a Mach–Zehnder interferometer. The quantum computer is set in a superposition of \"not running\" and \"running\" states by means such as the Quantum Zeno Effect. Those state histories are quantum interfered. After many repetitions of very rapid projective measurements, the \"not running\" state evolves to a final value imprinted into the properties of the quantum computer. Measuring that value allows for learning the result of some types of computations such as Grover's algorithm even though the result was derived from the non-running state of the quantum computer.\n",
      "\n",
      "Ġnon\n",
      "645 21\n",
      "De-excitation from the excited singlet state to the ground state also occurs by other mechanisms, such as non-radiant thermal decay or ‘phosphorescence’. In the latter case, the chromophore undergoes a forbidden transition from the excited singlet state into the triplet state (intersystem crossing, ISC, Fig 2.4), which has a non-zero probability, for example because of spin orbit coupling of the electrons’ magnetic moments\"\n",
      "\n",
      "Ġnon\n",
      "645 22\n",
      "De-excitation from the excited singlet state to the ground state also occurs by other mechanisms, such as non-radiant thermal decay or ‘phosphorescence’. In the latter case, the chromophore undergoes a forbidden transition from the excited singlet state into the triplet state (intersystem crossing, ISC, Fig 2.4), which has a non-zero probability, for example because of spin orbit coupling of the electrons’ magnetic moments\"\n",
      "\n",
      "-\n",
      "645 69\n",
      "De-excitation from the excited singlet state to the ground state also occurs by other mechanisms, such as non-radiant thermal decay or ‘phosphorescence’. In the latter case, the chromophore undergoes a forbidden transition from the excited singlet state into the triplet state (intersystem crossing, ISC, Fig 2.4), which has a non-zero probability, for example because of spin orbit coupling of the electrons’ magnetic moments\"\n",
      "\n",
      "Ġnon\n",
      "651 114\n",
      "A composite optical microcavity, in which nitrogen vacancy (NV) centers in a diamond nanopillar are coupled to whispering gallery modes in a silica microsphere, is demonstrated. Nanopillars with a diameter as small as 200 nm are fabricated from a bulk diamond crystal by reactive ion etching and are positioned with nanometer precision near the equator of a silica microsphere. The composite nanopillar-microsphere system overcomes the poor controllability of a nanocrystal-based microcavity system and takes full advantage of the exceptional spin properties of NV centers and the ultrahigh quality factor of silica microspheres.\n",
      "\n",
      "Ġultra\n",
      "700 14\n",
      "which must become the GROUND STATE of the ANCILLA upon non-classical correlation..\n",
      "\n",
      "Ġnon\n",
      "704 49\n",
      "We investigate theoretically how the spectroscopy of an ancillary qubit can probe cavity (circuit) QED ground states containing photons. We consider three classes of systems (Dicke, Tavis-Cummings and Hopfield-like models), where non-trivial vacua are the result of ultrastrong coupling between N two-level systems and a single-mode bosonic field. An ancillary qubit detuned with respect to the boson frequency is shown to reveal distinct spectral signatures depending on the type of vacua. In particular, the Lamb shift of the ancilla is sensitive to both ground state photon population and correlations. Back-action of the ancilla on the cavity ground state is investigated, taking into account the dissipation via a consistent master equation for the ultrastrong coupling regime. The conditions for high-fidelity measurements are determined.\n",
      "\n",
      "Ġnon\n",
      "704 50\n",
      "We investigate theoretically how the spectroscopy of an ancillary qubit can probe cavity (circuit) QED ground states containing photons. We consider three classes of systems (Dicke, Tavis-Cummings and Hopfield-like models), where non-trivial vacua are the result of ultrastrong coupling between N two-level systems and a single-mode bosonic field. An ancillary qubit detuned with respect to the boson frequency is shown to reveal distinct spectral signatures depending on the type of vacua. In particular, the Lamb shift of the ancilla is sensitive to both ground state photon population and correlations. Back-action of the ancilla on the cavity ground state is investigated, taking into account the dissipation via a consistent master equation for the ultrastrong coupling regime. The conditions for high-fidelity measurements are determined.\n",
      "\n",
      "-\n",
      "770 10\n",
      "now Imagine statistical ensembles being observed in real time via non-classical entanglement\n",
      "\n",
      "Ġnon\n",
      "850 25\n",
      "My husband nervously drove us to the hospital as if the baby would pop out any second. I had to remind him to not worry. Things usually didn’t happen that fast for first-time moms (or at least I hoped it wouldn’t). I had to go by instinct although in the back of my mind, I wasn’t sure what would happen next.\n",
      "\n",
      "Ġnot\n",
      "860 17\n",
      "A couple hours later, I was FINALLY admitted. My husband kept asking me questions non-stop about what I wanted, needed, and more. All I could say was “if I need something, I’ll let you know. Thanks.” I literally couldn’t talk. I felt like vomiting and had heart burn for the first time in my life.\n",
      "\n",
      "Ġnon\n",
      "868 125\n",
      "There were no walking epidurals available though and I didn’t want to take narcotics (which could make me dizzy), so I continued along, breathing away. A bath was an option too and this I requested and wanted. I was so uncomfortable as things progressed. I couldn’t get in the shower to relax my muscles, but somehow a bath sounded soothing and worth the effort. As soon as the bath was ready, however, I suddenly felt a pop down below as if major pressure had been released from my insides. Immediately, there was a shift. The back and butt pressure/pain I felt was no longer there. It was time to push! I knew as soon as I felt it.\n",
      "\n",
      "Ġno\n",
      "980 19\n",
      "This is the only certain way to center the text inside a TextView object or one of its subclasses.\n",
      "\n",
      "Ġsub\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Layer 3  \\\n",
    "Index. My interpretation. Mean value  \\\n",
    "21821. Month. 2.07150  \\\n",
    "6122. Hyphen in Hyphenated words. 2.58  \\\n",
    "32061. Parenthesis. 2.44  \\\n",
    "25956. Want to say abbreviations/captilization. 2.30  \\\n",
    "29401. Prefixes like un, non, re. 1.67  \\\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T00:01:47.143070Z",
     "start_time": "2025-03-13T00:01:47.139307Z"
    }
   },
   "cell_type": "code",
   "source": "# While generating, I need to get the activations from the model. Send it to the sae with the weight of an index clamped to 5. Then reinject those back into the model. I will look at Colin's script for this. ",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T20:20:25.533903Z",
     "start_time": "2025-03-13T20:20:24.453666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from inference import Pythia70Model\n",
    "\n",
    "# Use Colin's code to modify inference. \n",
    "seventy_m_model = Pythia70Model()\n",
    "seventy_m_model.clamping(\"We took a\", \"dictionaries/pythia-70m-deduped/mlp_out_layer3/10_32768/ae.pt\", do_clamping=False, clamping_layer=3, clamping_index=6122, clamping_value=5.0)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We took a look at the two-']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T20:19:18.658295Z",
     "start_time": "2025-03-13T20:19:17.586226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from inference import Pythia70Model\n",
    "\n",
    "# Use Colin's code to modify inference. \n",
    "seventy_m_model = Pythia70Model()\n",
    "seventy_m_model.clamping(\"We took a\", \"dictionaries/pythia-70m-deduped/mlp_out_layer3/10_32768/ae.pt\", do_clamping=True, clamping_layer=3, clamping_index=6122, clamping_value=5.0)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We took a--- rather-']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T20:32:04.914237Z",
     "start_time": "2025-03-13T20:32:03.956147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from inference import Pythia70Model\n",
    "\n",
    "# Use Colin's code to modify inference. \n",
    "seventy_m_model = Pythia70Model()\n",
    "seventy_m_model.clamping(\"The leaves change colour and fall from the trees in\", \"dictionaries/pythia-70m-deduped/mlp_out_layer3/10_32768/ae.pt\", do_clamping=True, clamping_layer=3, clamping_index=6122, clamping_value=5.0)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next token tensor(253)\n",
      "Next token tensor(187)\n",
      "Next token tensor(2366)\n",
      "Next token tensor(15)\n",
      "Next token tensor(187)\n",
      "['The leaves change colour and fall from the trees in the\\n together.\\n']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T19:55:34.466703Z",
     "start_time": "2025-03-13T19:55:34.379878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Outputs before my stuff\n",
    "test_input = \"I'm feeling a bit\" \n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(test_input, return_tensors=\"pt\", padding=\"max_length\", truncation = True)\n",
    "attention_mask = inputs['attention_mask']  # Get the attention_mask\n",
    "with torch.no_grad():\n",
    "    output = model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "\n",
    "# Decode the output\n",
    "decoded_output = tokenizer.decode(output[0].tolist(), skip_special_tokens=True)\n",
    "\n",
    "# Print decoded output\n",
    "print(decoded_output)\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m test_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvery pilot needs a\u001B[39m\u001B[38;5;124m\"\u001B[39m \n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Tokenize the input\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m(test_input, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_length\u001B[39m\u001B[38;5;124m\"\u001B[39m, truncation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      6\u001B[0m attention_mask \u001B[38;5;241m=\u001B[39m inputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;66;03m# Get the attention_mask\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Talk to me. I'm not sure I'm going to be able to do that. I'm not sure I  \\ \n",
    "\n",
    "The word of the day is the same as the word of the day.  \\\n",
    "\n",
    "The mental health of the patient is not the same as the physical health of the patient. The mental health of  \\\n",
    "\n",
    "0.67 is the highest value of 0.67  \\\n",
    "\n",
    "Every pilot needs a new set of skills to be used in the future.  \\\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T21:20:44.403287Z",
     "start_time": "2025-02-18T21:20:44.398010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "acts_np = decoded_activations.detach().numpy()\n",
    "# Arbitrary threshold\n",
    "print(len(acts_np[acts_np > 1]))\n",
    "# non_zero_indices = np.nonzero(decoded_activations)\n",
    "# print(non_zero_indices.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T21:21:55.911974Z",
     "start_time": "2025-02-18T21:21:55.908624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "acts_np_thresh = acts_np[acts_np > 1]\n",
    "print(acts_np_thresh.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35,)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T21:21:57.655951Z",
     "start_time": "2025-02-18T21:21:57.648385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Weight scaling\n",
    "\n",
    "\n",
    "# What part of the decoded outputs are significant?\n",
    "# Considering non-zero indices for now\n",
    "\n",
    "# Scale all the indices by 10\n",
    "# weight[acts_np_thresh] *= 5\n",
    "\n",
    "# Add 5 bias to all the non-zero indices\n",
    "bias[acts_np_thresh] += 5\n",
    "\n",
    "# write back to the model\n",
    "state_dict['mlp.dense_4h_to_h.weight'] = weight\n",
    "state_dict['mlp.dense_4h_to_h.bias'] = bias\n",
    "\n",
    "model.gpt_neox.layers[3].load_state_dict(state_dict)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T21:22:04.994742Z",
     "start_time": "2025-02-18T21:22:04.668869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  Test out hypothesis\n",
    "\n",
    "# Tokenize the input\n",
    "\n",
    "# Is there a better way to do this?\n",
    "# Pass the tokenized input through the model\n",
    "# Tokenize the input\n",
    "test_input = \"I like eating\"\n",
    "inputs = tokenizer(test_input, return_tensors=\"pt\", padding=\"max_length\", truncation = True)\n",
    "attention_mask = inputs['attention_mask']  # Get the attention_mask\n",
    "with torch.no_grad():\n",
    "    output = model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "\n",
    "# Decode the output\n",
    "decoded_output = tokenizer.decode(output[0].tolist(), skip_special_tokens=True)\n",
    "\n",
    "# Print decoded output\n",
    "print(decoded_output)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like eating a lot of a long time to the dayly and to the dayly and to the dayly\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 92,
   "source": [
    "# # Analyze which features activate for specific tokens\n",
    "# top_n = 800  \n",
    "# top_features = []\n",
    "\n",
    "# for sentence_idx, per_token_features in enumerate(sparse_representations):\n",
    "#     sentence_top_features = []\n",
    "    \n",
    "#     for token_idx, features in enumerate(per_token_features):\n",
    "#         # Extract top N active features for this token\n",
    "#         top_indices = np.argsort(features)[-top_n:][::-1]\n",
    "#         sentence_top_features.append(set(top_indices))\n",
    "    \n",
    "#     top_features.append(sentence_top_features)  # Store per-token top feature indices\n",
    "\n",
    "# # Example: Print feature activations for each token in the first sentence\n",
    "# tokenized_sentence = tokenizer(sentences[0])['input_ids']\n",
    "# decoded_tokens = tokenizer.convert_ids_to_tokens(tokenized_sentence)\n",
    "\n",
    "# print(\"\\nFeature activations for the first sentence:\")\n",
    "# for token, feature_set in zip(decoded_tokens, top_features[0]):\n",
    "#     print(f\"Token: {token}, Top Features: {list(feature_set)[:10]}\")  # Show top 5 features\n",
    "\n",
    "#     # Example: Print feature activations for each token in the first sentence\n",
    "# tokenized_sentence = tokenizer(sentences[1])['input_ids']\n",
    "# decoded_tokens = tokenizer.convert_ids_to_tokens(tokenized_sentence)\n",
    "\n",
    "# print(\"\\nFeature activations for the first sentence:\")\n",
    "# for token, feature_set in zip(decoded_tokens, top_features[0]):\n",
    "#     print(f\"Token: {token}, Top Features: {list(feature_set)[:10]}\")  # Show top 5 features\n",
    "    \n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T20:37:36.224345Z",
     "start_time": "2025-02-13T20:37:36.220370Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 18,
   "source": [
    "# Select the most frequently occurring features\n",
    "top_common_features = sorted(feature_counts, key=feature_counts.get, reverse=True)[:800]\n",
    "\n",
    "# # Create a synthetic sparse vector using these common features\n",
    "# synthetic_sparse_vector = np.zeros((32768,))  # Assume dictionary size is 32768\n",
    "# for idx in top_common_features:\n",
    "#     synthetic_sparse_vector[idx] = 1  # Set these features as active"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T20:37:46.213174Z",
     "start_time": "2025-02-13T20:37:46.210544Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(10900), np.int64(10969), np.int64(10968), np.int64(10918), np.int64(10919), np.int64(10967), np.int64(10966), np.int64(10920), np.int64(10965), np.int64(10921)]\n"
     ]
    }
   ],
   "execution_count": 19,
   "source": "print(top_common_features[:10])"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode sparse vector back into model space\n",
    "synthetic_dense_vector = ae.decode(torch.tensor(synthetic_sparse_vector).float()).detach().cpu()\n",
    "synthetic_dense_vector *= 10  # Experiment with scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized input: ['The', 'Ġcapital', 'Ġof', 'Ġ', '<XYZ>', 'Ġis']\n"
     ]
    }
   ],
   "source": [
    "# Add a new special token\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': [\"<XYZ>\"]})\n",
    "model.resize_token_embeddings(len(tokenizer))  # Resize embeddings to include new token\n",
    "\n",
    "masked_sentence = \"The capital of <XYZ> is\"\n",
    "input_ids = tokenizer(masked_sentence, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "# Convert token IDs to tokens\n",
    "decoded_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "print(f\"Tokenized input: {decoded_tokens}\")  # Debugging\n",
    "\n",
    "# **Find the placeholder index**\n",
    "try:\n",
    "    placeholder_index = decoded_tokens.index(\"<XYZ>\")\n",
    "except ValueError:\n",
    "    raise ValueError(f\"Could not find placeholder token in: {decoded_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted token:  the\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert input_ids to embeddings\n",
    "model_inputs = model.get_input_embeddings()(input_ids)\n",
    "\n",
    "# Inject synthetic feature vector at the placeholder position\n",
    "model_inputs[:, placeholder_index, :] = synthetic_dense_vector\n",
    "\n",
    "# Generate text from modified embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs_embeds=model_inputs)\n",
    "    logits = outputs.logits[:, -1, :]  # Get last token logits\n",
    "    predicted_token_id = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "# Decode the predicted token\n",
    "predicted_word = tokenizer.decode([predicted_token_id])\n",
    "\n",
    "print(f\"Predicted token: {predicted_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
