{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tabulate import tabulate  \n",
    "from dictionary import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Moscow is in Russia.', 'Beijing is in China.', 'Athens is in Greece.', 'Berlin is in Germany.', 'Paris is in France.', 'London is in the United Kingdom.', 'Tokyo is in Japan.', 'Cairo is in Egypt.', 'Rome is in Italy.', 'Madrid is in Spain.', 'Lisbon is in Portugal.', 'Ottawa is in Canada.', 'Canberra is in Australia.', 'Brasília is in Brazil.', 'New Delhi is in India.', 'Washington, D.C. is in the United States.', 'Buenos Aires is in Argentina.', 'Mexico City is in Mexico.', 'Seoul is in South Korea.', 'Jakarta is in Indonesia.', 'Bangkok is in Thailand.', 'Oslo is in Norway.', 'Stockholm is in Sweden.', 'Helsinki is in Finland.', 'Warsaw is in Poland.', 'Vienna is in Austria.', 'Frank is a teacher.']\n"
     ]
    }
   ],
   "source": [
    "#Load sentences from CSV file\n",
    "df = pd.read_csv(\"sentences.csv\", delimiter=\",\", encoding=\"utf-8\", quotechar='\"')\n",
    "sentences = df['sentence'].tolist()\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Pythia model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m-deduped\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m-deduped\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing sentence: 'Moscow is in Russia.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[   46, 15635,   310,   275,  7422,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 6, 512])\n",
      "Output from layer: torch.Size([1, 6, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 6, 512])\n",
      "\n",
      "Processing sentence: 'Beijing is in China.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[ 4678, 16741,   310,   275,  4135,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 6, 512])\n",
      "Output from layer: torch.Size([1, 6, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 6, 512])\n",
      "\n",
      "Processing sentence: 'Athens is in Greece.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[   34, 49966,   310,   275, 17785,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 6, 512])\n",
      "Output from layer: torch.Size([1, 6, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 6, 512])\n",
      "\n",
      "Processing sentence: 'Berlin is in Germany.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[23666,  3642,   310,   275,  6176,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 6, 512])\n",
      "Output from layer: torch.Size([1, 6, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 6, 512])\n",
      "\n",
      "Processing sentence: 'Paris is in France.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[36062,   310,   275,  6181,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 5, 512])\n",
      "Output from layer: torch.Size([1, 5, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 5, 512])\n",
      "\n",
      "Processing sentence: 'London is in the United Kingdom.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[18868,   310,   275,   253,  1986, 11491,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 7, 512])\n",
      "Output from layer: torch.Size([1, 7, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 7, 512])\n",
      "\n",
      "Processing sentence: 'Tokyo is in Japan.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[32040, 11904,   310,   275,  4047,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 6, 512])\n",
      "Output from layer: torch.Size([1, 6, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 6, 512])\n",
      "\n",
      "Processing sentence: 'Cairo is in Egypt.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[   36, 22466,   310,   275, 10253,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 6, 512])\n",
      "Output from layer: torch.Size([1, 6, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 6, 512])\n",
      "\n",
      "Processing sentence: 'Rome is in Italy.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[  51,  485,  310,  275, 9972,   15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 6, 512])\n",
      "Output from layer: torch.Size([1, 6, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 6, 512])\n",
      "\n",
      "Processing sentence: 'Madrid is in Spain.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[19008,  6992,   310,   275, 11268,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 6, 512])\n",
      "Output from layer: torch.Size([1, 6, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 6, 512])\n",
      "\n",
      "Processing sentence: 'Lisbon is in Portugal.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[   45,   261,  4006,   310,   275, 24084,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 7, 512])\n",
      "Output from layer: torch.Size([1, 7, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 7, 512])\n",
      "\n",
      "Processing sentence: 'Ottawa is in Canada.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[43468, 26629,   310,   275,  6144,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 6, 512])\n",
      "Output from layer: torch.Size([1, 6, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 6, 512])\n",
      "\n",
      "Processing sentence: 'Canberra is in Australia.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[5804,  589,  376,  310,  275, 6976,   15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 7, 512])\n",
      "Output from layer: torch.Size([1, 7, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 7, 512])\n",
      "\n",
      "Processing sentence: 'Brasília is in Brazil.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[   35,  6230,  1950, 19702,   310,   275, 10869,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 8, 512])\n",
      "Output from layer: torch.Size([1, 8, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 8, 512])\n",
      "\n",
      "Processing sentence: 'New Delhi is in India.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[ 4257, 19950,   310,   275,  5427,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 6, 512])\n",
      "Output from layer: torch.Size([1, 6, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 6, 512])\n",
      "\n",
      "Processing sentence: 'Washington, D.C. is in the United States.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[25655,    13,   399,    15,    36,    15,   310,   275,   253,  1986,\n",
      "          2077,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 12, 512])\n",
      "Output from layer: torch.Size([1, 12, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 12, 512])\n",
      "\n",
      "Processing sentence: 'Buenos Aires is in Argentina.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[ 9263, 32564, 45561,   310,   275, 23881,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 7, 512])\n",
      "Output from layer: torch.Size([1, 7, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 7, 512])\n",
      "\n",
      "Processing sentence: 'Mexico City is in Mexico.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[48273,  3228,   310,   275,  8987,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 6, 512])\n",
      "Output from layer: torch.Size([1, 6, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 6, 512])\n",
      "\n",
      "Processing sentence: 'Seoul is in South Korea.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[3251, 3941,  310,  275, 3684, 9733,   15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 7, 512])\n",
      "Output from layer: torch.Size([1, 7, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 7, 512])\n",
      "\n",
      "Processing sentence: 'Jakarta is in Indonesia.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[   43,   518, 37964,   310,   275, 23340,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 7, 512])\n",
      "Output from layer: torch.Size([1, 7, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 7, 512])\n",
      "\n",
      "Processing sentence: 'Bangkok is in Thailand.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[   35,   606, 39052,   310,   275, 23174,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 7, 512])\n",
      "Output from layer: torch.Size([1, 7, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 7, 512])\n",
      "\n",
      "Processing sentence: 'Oslo is in Norway.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[   48, 37953,   310,   275, 20341,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 6, 512])\n",
      "Output from layer: torch.Size([1, 6, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 6, 512])\n",
      "\n",
      "Processing sentence: 'Stockholm is in Sweden.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[35484, 26666,   310,   275, 16842,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 6, 512])\n",
      "Output from layer: torch.Size([1, 6, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 6, 512])\n",
      "\n",
      "Processing sentence: 'Helsinki is in Finland.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[   41,  1241, 31609,   310,   275, 25270,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 7, 512])\n",
      "Output from layer: torch.Size([1, 7, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 7, 512])\n",
      "\n",
      "Processing sentence: 'Warsaw is in Poland.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[   56,  1032,  1403,   310,   275, 16795,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 7, 512])\n",
      "Output from layer: torch.Size([1, 7, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 7, 512])\n",
      "\n",
      "Processing sentence: 'Vienna is in Austria.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[   55, 22890,   310,   275, 21753,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n",
      "Input to layer: torch.Size([1, 6, 512])\n",
      "Output from layer: torch.Size([1, 6, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 6, 512])\n",
      "\n",
      "Processing sentence: 'Frank is a teacher.'\n",
      "Tokenized input_ids_batch: {'input_ids': tensor([[20655,   310,   247,  9732,    15]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n",
      "Running model on the single sentence...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to layer: torch.Size([1, 5, 512])\n",
      "Output from layer: torch.Size([1, 5, 512])\n",
      "Model run completed\n",
      "Number of activations added: 1\n",
      "Activations for the sentence: torch.Size([1, 5, 512])\n",
      "\n",
      "All individual activations captured:\n",
      "Sentence 1 activations shape: torch.Size([1, 6, 512])\n",
      "Sentence 2 activations shape: torch.Size([1, 6, 512])\n",
      "Sentence 3 activations shape: torch.Size([1, 6, 512])\n",
      "Sentence 4 activations shape: torch.Size([1, 6, 512])\n",
      "Sentence 5 activations shape: torch.Size([1, 5, 512])\n",
      "Sentence 6 activations shape: torch.Size([1, 7, 512])\n",
      "Sentence 7 activations shape: torch.Size([1, 6, 512])\n",
      "Sentence 8 activations shape: torch.Size([1, 6, 512])\n",
      "Sentence 9 activations shape: torch.Size([1, 6, 512])\n",
      "Sentence 10 activations shape: torch.Size([1, 6, 512])\n",
      "Sentence 11 activations shape: torch.Size([1, 7, 512])\n",
      "Sentence 12 activations shape: torch.Size([1, 6, 512])\n",
      "Sentence 13 activations shape: torch.Size([1, 7, 512])\n",
      "Sentence 14 activations shape: torch.Size([1, 8, 512])\n",
      "Sentence 15 activations shape: torch.Size([1, 6, 512])\n",
      "Sentence 16 activations shape: torch.Size([1, 12, 512])\n",
      "Sentence 17 activations shape: torch.Size([1, 7, 512])\n",
      "Sentence 18 activations shape: torch.Size([1, 6, 512])\n",
      "Sentence 19 activations shape: torch.Size([1, 7, 512])\n",
      "Sentence 20 activations shape: torch.Size([1, 7, 512])\n",
      "Sentence 21 activations shape: torch.Size([1, 7, 512])\n",
      "Sentence 22 activations shape: torch.Size([1, 6, 512])\n",
      "Sentence 23 activations shape: torch.Size([1, 6, 512])\n",
      "Sentence 24 activations shape: torch.Size([1, 7, 512])\n",
      "Sentence 25 activations shape: torch.Size([1, 7, 512])\n",
      "Sentence 26 activations shape: torch.Size([1, 6, 512])\n",
      "Sentence 27 activations shape: torch.Size([1, 5, 512])\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "activation_list = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    \"\"\"Hook function to capture activations from the 4th MLP layer.\"\"\"\n",
    "    # Print input and output shapes for each token\n",
    "    print(f\"Input to layer: {input[0].shape}\")  # Input shape\n",
    "    print(f\"Output from layer: {output.shape}\")  # Output shape\n",
    "    \n",
    "    # Capture the activations\n",
    "    activation_list.append(output)\n",
    "\n",
    "# Hooking layer at index 3 (4th layer)\n",
    "layer_to_hook = model.gpt_neox.layers[3].mlp\n",
    "hook = layer_to_hook.register_forward_hook(hook_fn)\n",
    "\n",
    "individual_activations = []  # Store activations for each sentence separately\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(f\"\\nProcessing sentence: '{sentence}'\")\n",
    "    \n",
    "    # Tokenize the single sentence\n",
    "    input_ids_batch = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    print(f\"Tokenized input_ids_batch: {input_ids_batch}\")\n",
    "    \n",
    "    print(\"Running model on the single sentence...\")\n",
    "    output = model(**input_ids_batch)\n",
    "    print(\"Model run completed\")\n",
    "    \n",
    "    # Retrieve activations from MLP layer for this sentence\n",
    "    if activation_list:\n",
    "        print(f\"Number of activations added: {len(activation_list)}\")\n",
    "        activations = activation_list[-1]  # Get the last activation (corresponding to this sentence)\n",
    "        individual_activations.append(activations)\n",
    "        print(f\"Activations for the sentence: {activations.shape}\")\n",
    "    else:\n",
    "        print(\"No activations captured for this sentence.\")\n",
    "    \n",
    "    # Clear activation list after each sentence to capture activations separately for the next sentence\n",
    "    activation_list.clear()\n",
    "\n",
    "# Print all individual activations\n",
    "print(\"\\nAll individual activations captured:\")\n",
    "for idx, activations in enumerate(individual_activations):\n",
    "    print(f\"Sentence {idx+1} activations shape: {activations.shape}\")\n",
    "\n",
    "print(len(individual_activations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations shape before reshaping: torch.Size([1, 6, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 6, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 6, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 6, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 5, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 7, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 6, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 6, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 6, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 6, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 7, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 6, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 7, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 8, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 6, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 12, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 7, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 6, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 7, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 7, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 7, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 6, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 6, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 7, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 7, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 6, 512])\n",
      "Activations shape before reshaping: torch.Size([1, 5, 512])\n",
      "27\n",
      "(1, 6, 32768)\n",
      "Shared Top Features: {18192, 7082, 21462, 20383}\n"
     ]
    }
   ],
   "source": [
    "from dictionary import AutoEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "ae = AutoEncoder.from_pretrained(\n",
    "    \"dictionaries/pythia-70m-deduped/mlp_out_layer3/10_32768/ae.pt\", \n",
    "    map_location=torch.device('cpu')\n",
    ")\n",
    "\n",
    "sparse_representations = []  # Store the sparse representations for all sentences\n",
    "\n",
    "# Collect the sparse representations for all sentences\n",
    "for activations in individual_activations:\n",
    "    print(f\"Activations shape before reshaping: {activations.shape}\")\n",
    "    features = ae.encode(activations)  # Get the sparse feature representation\n",
    "    sparse_representations.append(features.detach().cpu().numpy())  # Store sparse features as NumPy array for analysis\n",
    "\n",
    "\n",
    "print(len(sparse_representations))\n",
    "print(sparse_representations[0].shape)\n",
    "\n",
    "top_features = []\n",
    "top_n = 800  # Number of top features to extract per sentence\n",
    "\n",
    "for features in sparse_representations:\n",
    "    features = features.flatten()  # Convert to 1D\n",
    "    top_indices = np.argsort(features)[-top_n:][::-1]  # Get indices of top 5 active features\n",
    "    top_features.append(set(top_indices))  # Store as a set\n",
    "    top_values = features[top_indices]  # Get the values of the top features\n",
    "#     print(f\"Top {top_n} features for current sentence: {list(zip(top_indices, top_values))}\")\n",
    "\n",
    "# Find shared features across all sentences\n",
    "shared_features = set.intersection(*top_features)\n",
    "print(\"Shared Top Features:\", shared_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 20383 is out of bounds for axis 0 with size 61",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m vectorizer\u001b[38;5;241m.\u001b[39mfit(sentences)  \u001b[38;5;66;03m# Assuming sentences is your list of input sentences\u001b[39;00m\n\u001b[1;32m      5\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n\u001b[0;32m----> 7\u001b[0m feature_20383 \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_names\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m20383\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Get the feature name for the index\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature 20383 corresponds to the word: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature_20383\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 20383 is out of bounds for axis 0 with size 61"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
