{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from dictionary import AutoEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Black is technically the absence of visible light, which makes it pretty fascinating when you think about it.', 'You know, black is one of those colors that just never goes out of style.', 'It’s interesting how black is often associated with sophistication and elegance—think of a classic black tuxedo.', 'In many cultures, black symbolizes mystery, power, and sometimes mourning.', 'Black holes are some of the most mysterious objects in the universe—they’re literally regions where light can’t escape.', 'When it comes to fashion, black is the go-to color for a timeless, sleek look.', 'Isn’t it cool how black objects absorb more heat because they absorb all wavelengths of light?', 'Matte black has such a modern, bold aesthetic—it’s so popular in car designs these days.', 'Black is often used in branding when companies want to convey authority and reliability.', 'Ever notice how black makes other colors stand out more when used as a background?', 'In photography, black-and-white images have this timeless, emotional feel that color photos don’t always capture.', 'Some animals, like black panthers, use their dark fur as camouflage for hunting at night.', 'Black has different meanings around the world—for example, in some cultures, it’s a color of mourning, while in others, it represents strength.', 'I always find it cool how black ink has been the standard for writing for centuries.', 'Black is the only color that can make a room feel both cozy and dramatic depending on the lighting.', 'Black cats are surrounded by superstitions, but in many places, they’re actually seen as good luck.', 'In design, black often symbolizes simplicity and minimalism—just think of brands like Apple.', 'Black is a color of contrasts—it can mean rebellion or authority, mystery or clarity, depending on the context.', 'A black night sky without city lights always makes me feel like I’m staring into infinity.', 'The night sky looks so much more vast when it’s pitch black without city lights.', 'There’s something timeless about a black leather jacket—it never goes out of style.', 'In space, a black hole bends light and warps time in ways we barely understand.', 'A sleek, black car always turns heads, especially with a glossy finish.', 'Many animals use black markings for camouflage or communication.', 'Artists often use black to add contrast and depth to their work.', 'Freshly brewed coffee always looks richer when it’s pure black.', 'Crows and ravens aren’t just black; their feathers shimmer with iridescent hues in sunlight.', 'Formal events often call for classic black attire.', 'The volcanic beaches in Iceland are covered in black sand.', 'When it comes to tattoos, black ink tends to last the longest.', 'Ultraviolet light is just beyond what we see as black in the visible spectrum.', 'Luxury brands often choose black packaging to convey exclusivity.', 'Ancient Egyptians used black eyeliner as part of their daily routine.', 'If you’ve ever driven on black ice, you know how dangerous it can be.', 'The fur of a black panther helps it stay hidden in dense forests.', 'In many cultures, black is seen as a color of mystery and power.', 'The black stripes on a zebra help it confuse predators.', 'Fashion designers love using black for its elegant simplicity.', 'The petals of some rare flowers have a velvety black hue.', 'Meteorites often look burnt and black after passing through Earth’s atmosphere.', 'The black plumage of ravens has long been associated with omens and myths.', 'Photographers sometimes use black backdrops to make their subjects pop.', \"There's a reason why black is the most common text color—it’s the easiest to read.\", 'Lava rock, once cooled, turns into a rough black surface.', 'Many predators use black coloring to help them stay hidden at night.', 'The black keys on a piano are just as important as the white ones.', 'Some butterflies have intricate black patterns on their wings for camouflage.', 'A room with black walls can feel cozy or intense, depending on the lighting.', 'The black bands on a snake can sometimes signal danger to predators.', 'Inkjet printers typically rely on black ink more than any other color.', 'Some gemstones, like black onyx, have been worn as protective talismans.', 'The black soot left behind after a fire tells a story of what burned.', 'X-rays don’t pass through bones, which show up as white against the black background.', 'Movie villains often wear black to create an aura of mystery or danger.', 'The black patterns on a Dalmatian’s coat are unique to each dog.', 'Many modern gadgets come in a sleek, matte black finish.', 'The black wings of a raven glisten with hints of blue and purple in sunlight.', 'Shadows on the moon appear as black patches due to the lack of atmosphere.', 'Fashion designers say every wardrobe needs a good black outfit.']\n"
     ]
    }
   ],
   "source": [
    "# Load sentences from CSV file\n",
    "df = pd.read_csv(\"sentences.csv\", delimiter=\",\", encoding=\"utf-8\", quotechar='\"')\n",
    "sentences = df['sentence'].tolist()\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Pythia model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m-deduped\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m-deduped\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized output: ['You', 'Ġknow', ',', 'Ġblack', 'Ġis', 'Ġone', 'Ġof', 'Ġthose', 'Ġcolors', 'Ġthat', 'Ġjust', 'Ġnever', 'Ġgoes', 'Ġout', 'Ġof', 'Ġstyle', '.']\n"
     ]
    }
   ],
   "source": [
    "# Testing tokenizer \n",
    "sentence = \"You know, black is one of those colors that just never goes out of style.\"\n",
    "tokenized_sentence = tokenizer(sentence)['input_ids']\n",
    "decoded_tokens = tokenizer.convert_ids_to_tokens(tokenized_sentence)\n",
    "\n",
    "print(\"Tokenized output:\", decoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_list = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    \"\"\"Hook function to capture activations from the 4th MLP layer.\"\"\"\n",
    "    activation_list.append(output)\n",
    "\n",
    "# Hook 4th MLP layer (index 3)\n",
    "layer_to_hook = model.gpt_neox.layers[3].mlp\n",
    "hook = layer_to_hook.register_forward_hook(hook_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 'Black is technically the absence of visible light, which makes it pretty fascinating when you think about it.'\n",
      "\n",
      "Processing: 'You know, black is one of those colors that just never goes out of style.'\n",
      "\n",
      "Processing: 'It’s interesting how black is often associated with sophistication and elegance—think of a classic black tuxedo.'\n",
      "\n",
      "Processing: 'In many cultures, black symbolizes mystery, power, and sometimes mourning.'\n",
      "\n",
      "Processing: 'Black holes are some of the most mysterious objects in the universe—they’re literally regions where light can’t escape.'\n",
      "\n",
      "Processing: 'When it comes to fashion, black is the go-to color for a timeless, sleek look.'\n",
      "\n",
      "Processing: 'Isn’t it cool how black objects absorb more heat because they absorb all wavelengths of light?'\n",
      "\n",
      "Processing: 'Matte black has such a modern, bold aesthetic—it’s so popular in car designs these days.'\n",
      "\n",
      "Processing: 'Black is often used in branding when companies want to convey authority and reliability.'\n",
      "\n",
      "Processing: 'Ever notice how black makes other colors stand out more when used as a background?'\n",
      "\n",
      "Processing: 'In photography, black-and-white images have this timeless, emotional feel that color photos don’t always capture.'\n",
      "\n",
      "Processing: 'Some animals, like black panthers, use their dark fur as camouflage for hunting at night.'\n",
      "\n",
      "Processing: 'Black has different meanings around the world—for example, in some cultures, it’s a color of mourning, while in others, it represents strength.'\n",
      "\n",
      "Processing: 'I always find it cool how black ink has been the standard for writing for centuries.'\n",
      "\n",
      "Processing: 'Black is the only color that can make a room feel both cozy and dramatic depending on the lighting.'\n",
      "\n",
      "Processing: 'Black cats are surrounded by superstitions, but in many places, they’re actually seen as good luck.'\n",
      "\n",
      "Processing: 'In design, black often symbolizes simplicity and minimalism—just think of brands like Apple.'\n",
      "\n",
      "Processing: 'Black is a color of contrasts—it can mean rebellion or authority, mystery or clarity, depending on the context.'\n",
      "\n",
      "Processing: 'A black night sky without city lights always makes me feel like I’m staring into infinity.'\n",
      "\n",
      "Processing: 'The night sky looks so much more vast when it’s pitch black without city lights.'\n",
      "\n",
      "Processing: 'There’s something timeless about a black leather jacket—it never goes out of style.'\n",
      "\n",
      "Processing: 'In space, a black hole bends light and warps time in ways we barely understand.'\n",
      "\n",
      "Processing: 'A sleek, black car always turns heads, especially with a glossy finish.'\n",
      "\n",
      "Processing: 'Many animals use black markings for camouflage or communication.'\n",
      "\n",
      "Processing: 'Artists often use black to add contrast and depth to their work.'\n",
      "\n",
      "Processing: 'Freshly brewed coffee always looks richer when it’s pure black.'\n",
      "\n",
      "Processing: 'Crows and ravens aren’t just black; their feathers shimmer with iridescent hues in sunlight.'\n",
      "\n",
      "Processing: 'Formal events often call for classic black attire.'\n",
      "\n",
      "Processing: 'The volcanic beaches in Iceland are covered in black sand.'\n",
      "\n",
      "Processing: 'When it comes to tattoos, black ink tends to last the longest.'\n",
      "\n",
      "Processing: 'Ultraviolet light is just beyond what we see as black in the visible spectrum.'\n",
      "\n",
      "Processing: 'Luxury brands often choose black packaging to convey exclusivity.'\n",
      "\n",
      "Processing: 'Ancient Egyptians used black eyeliner as part of their daily routine.'\n",
      "\n",
      "Processing: 'If you’ve ever driven on black ice, you know how dangerous it can be.'\n",
      "\n",
      "Processing: 'The fur of a black panther helps it stay hidden in dense forests.'\n",
      "\n",
      "Processing: 'In many cultures, black is seen as a color of mystery and power.'\n",
      "\n",
      "Processing: 'The black stripes on a zebra help it confuse predators.'\n",
      "\n",
      "Processing: 'Fashion designers love using black for its elegant simplicity.'\n",
      "\n",
      "Processing: 'The petals of some rare flowers have a velvety black hue.'\n",
      "\n",
      "Processing: 'Meteorites often look burnt and black after passing through Earth’s atmosphere.'\n",
      "\n",
      "Processing: 'The black plumage of ravens has long been associated with omens and myths.'\n",
      "\n",
      "Processing: 'Photographers sometimes use black backdrops to make their subjects pop.'\n",
      "\n",
      "Processing: 'There's a reason why black is the most common text color—it’s the easiest to read.'\n",
      "\n",
      "Processing: 'Lava rock, once cooled, turns into a rough black surface.'\n",
      "\n",
      "Processing: 'Many predators use black coloring to help them stay hidden at night.'\n",
      "\n",
      "Processing: 'The black keys on a piano are just as important as the white ones.'\n",
      "\n",
      "Processing: 'Some butterflies have intricate black patterns on their wings for camouflage.'\n",
      "\n",
      "Processing: 'A room with black walls can feel cozy or intense, depending on the lighting.'\n",
      "\n",
      "Processing: 'The black bands on a snake can sometimes signal danger to predators.'\n",
      "\n",
      "Processing: 'Inkjet printers typically rely on black ink more than any other color.'\n",
      "\n",
      "Processing: 'Some gemstones, like black onyx, have been worn as protective talismans.'\n",
      "\n",
      "Processing: 'The black soot left behind after a fire tells a story of what burned.'\n",
      "\n",
      "Processing: 'X-rays don’t pass through bones, which show up as white against the black background.'\n",
      "\n",
      "Processing: 'Movie villains often wear black to create an aura of mystery or danger.'\n",
      "\n",
      "Processing: 'The black patterns on a Dalmatian’s coat are unique to each dog.'\n",
      "\n",
      "Processing: 'Many modern gadgets come in a sleek, matte black finish.'\n",
      "\n",
      "Processing: 'The black wings of a raven glisten with hints of blue and purple in sunlight.'\n",
      "\n",
      "Processing: 'Shadows on the moon appear as black patches due to the lack of atmosphere.'\n",
      "\n",
      "Processing: 'Fashion designers say every wardrobe needs a good black outfit.'\n",
      "Captured activations for 59 sentences.\n"
     ]
    }
   ],
   "source": [
    "# Store per-token activations\n",
    "individual_activations = []\n",
    "\n",
    "# Target values\n",
    "target_values = ['black','Black','ĠBlack','Ġblack']\n",
    "    \n",
    "for sentence in sentences:\n",
    "    print(f\"\\nProcessing: '{sentence}'\")\n",
    "    input_ids_batch = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    decoded_tokens = tokenizer.convert_ids_to_tokens(input_ids_batch['input_ids'][0])\n",
    "    model(**input_ids_batch)  # Forward pass to capture activations\n",
    "\n",
    "    target_idx = [i for i, word in enumerate(decoded_tokens) if word in target_values]\n",
    "\n",
    "    if not target_idx:\n",
    "        print(f\"Target word not found in sentence: {decoded_tokens}\")\n",
    "        continue\n",
    "    else:\n",
    "        target_idx = target_idx[0]\n",
    "\n",
    "    if activation_list:\n",
    "        activations = activation_list[-1].squeeze(0)  # Shape: (seq_len, hidden_dim)\n",
    "        individual_activations.append((activations,target_idx))\n",
    "    activation_list.clear()\n",
    "\n",
    "print(f\"Captured activations for {len(individual_activations)} sentences.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryansherby/Library/CloudStorage/OneDrive-Personal/Documents/Columbia/CRIS Lab Project/dictionary_learning/dictionary.py:133: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = t.load(path, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "# Load Dictionary Learning AutoEncoder\n",
    "ae = AutoEncoder.from_pretrained(\n",
    "    \"dictionaries/pythia-70m-deduped/mlp_out_layer3/10_32768/ae.pt\", \n",
    "    map_location=torch.device('cpu')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20 sentences into token-aligned sparse representations.\n"
     ]
    }
   ],
   "source": [
    "# Convert activations to sparse representations\n",
    "sparse_representations = []\n",
    "for activations in individual_activations:\n",
    "    sparse_repr = ae.encode(activations).detach().cpu().numpy()  # (seq_len, dict_size)\n",
    "    sparse_representations.append(sparse_repr)\n",
    "print(f\"Processed {len(sparse_representations)} sentences into token-aligned sparse representations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate features: Find top activated features across all tokens in all sentences\n",
    "feature_counts = {}\n",
    "for sentence_features in sparse_representations:\n",
    "    for token_features in sentence_features:\n",
    "        top_indices = np.argsort(token_features)[-800:][::-1]  # Top 800 features per token\n",
    "        for idx in top_indices:\n",
    "            feature_counts[idx] = feature_counts.get(idx, 0) + 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{20383: 39,\n",
       " 21462: 25,\n",
       " 7082: 14,\n",
       " 18192: 31,\n",
       " 9123: 9,\n",
       " 9109: 10,\n",
       " 31054: 8,\n",
       " 9312: 39,\n",
       " 9081: 12,\n",
       " 31330: 24,\n",
       " 18068: 3,\n",
       " 26245: 4,\n",
       " 29597: 13,\n",
       " 3054: 26,\n",
       " 18413: 4,\n",
       " 15852: 19,\n",
       " 15559: 7,\n",
       " 22072: 4,\n",
       " 19443: 5,\n",
       " 11928: 13,\n",
       " 2083: 16,\n",
       " 30233: 2,\n",
       " 23882: 15,\n",
       " 19206: 15,\n",
       " 16219: 7,\n",
       " 8305: 9,\n",
       " 22566: 14,\n",
       " 10887: 377,\n",
       " 26654: 26,\n",
       " 18194: 18,\n",
       " 1176: 38,\n",
       " 22463: 18,\n",
       " 15500: 17,\n",
       " 20890: 19,\n",
       " 3112: 8,\n",
       " 29932: 23,\n",
       " 24979: 1,\n",
       " 28308: 12,\n",
       " 1427: 11,\n",
       " 24646: 12,\n",
       " 14179: 52,\n",
       " 24194: 17,\n",
       " 16022: 25,\n",
       " 19007: 14,\n",
       " 27926: 29,\n",
       " 3778: 8,\n",
       " 27215: 12,\n",
       " 22922: 30,\n",
       " 23812: 8,\n",
       " 19171: 27,\n",
       " 26631: 28,\n",
       " 24408: 14,\n",
       " 18719: 5,\n",
       " 32311: 37,\n",
       " 24440: 9,\n",
       " 23028: 7,\n",
       " 22800: 14,\n",
       " 26287: 27,\n",
       " 7132: 20,\n",
       " 25962: 38,\n",
       " 22593: 7,\n",
       " 5798: 29,\n",
       " 7793: 11,\n",
       " 6969: 13,\n",
       " 20369: 9,\n",
       " 7834: 14,\n",
       " 27226: 12,\n",
       " 12385: 12,\n",
       " 9785: 5,\n",
       " 578: 22,\n",
       " 31967: 18,\n",
       " 28529: 26,\n",
       " 13450: 7,\n",
       " 8071: 4,\n",
       " 7180: 3,\n",
       " 18268: 14,\n",
       " 12077: 17,\n",
       " 20977: 7,\n",
       " 20654: 24,\n",
       " 3858: 17,\n",
       " 11309: 19,\n",
       " 14034: 15,\n",
       " 26162: 1,\n",
       " 6023: 26,\n",
       " 24777: 17,\n",
       " 8683: 14,\n",
       " 11233: 63,\n",
       " 29649: 6,\n",
       " 20579: 7,\n",
       " 6310: 18,\n",
       " 30584: 17,\n",
       " 28580: 6,\n",
       " 5640: 4,\n",
       " 17041: 26,\n",
       " 23625: 21,\n",
       " 13125: 12,\n",
       " 5994: 10,\n",
       " 12343: 16,\n",
       " 31115: 12,\n",
       " 11856: 16,\n",
       " 10725: 32,\n",
       " 10995: 377,\n",
       " 13945: 18,\n",
       " 27095: 16,\n",
       " 19338: 21,\n",
       " 17427: 21,\n",
       " 12020: 16,\n",
       " 4983: 48,\n",
       " 24461: 14,\n",
       " 15608: 9,\n",
       " 13619: 27,\n",
       " 6865: 4,\n",
       " 15903: 14,\n",
       " 26516: 16,\n",
       " 933: 6,\n",
       " 30765: 22,\n",
       " 25544: 25,\n",
       " 13366: 18,\n",
       " 10983: 377,\n",
       " 6502: 30,\n",
       " 7838: 25,\n",
       " 20553: 22,\n",
       " 23710: 11,\n",
       " 10260: 122,\n",
       " 17989: 12,\n",
       " 21920: 25,\n",
       " 2085: 18,\n",
       " 6265: 11,\n",
       " 2244: 24,\n",
       " 200: 11,\n",
       " 26113: 19,\n",
       " 220: 16,\n",
       " 19346: 7,\n",
       " 13737: 15,\n",
       " 30930: 17,\n",
       " 23537: 18,\n",
       " 4206: 11,\n",
       " 15035: 6,\n",
       " 7859: 2,\n",
       " 9525: 31,\n",
       " 30877: 11,\n",
       " 23279: 43,\n",
       " 28749: 26,\n",
       " 8527: 20,\n",
       " 7775: 20,\n",
       " 7731: 4,\n",
       " 21646: 20,\n",
       " 10659: 4,\n",
       " 21565: 10,\n",
       " 7083: 1,\n",
       " 25088: 16,\n",
       " 10904: 377,\n",
       " 10900: 377,\n",
       " 10948: 377,\n",
       " 10947: 377,\n",
       " 10905: 377,\n",
       " 10906: 377,\n",
       " 10945: 377,\n",
       " 10946: 377,\n",
       " 10907: 377,\n",
       " 10902: 377,\n",
       " 10909: 377,\n",
       " 10763: 70,\n",
       " 10901: 377,\n",
       " 10776: 258,\n",
       " 10908: 377,\n",
       " 10903: 377,\n",
       " 10949: 377,\n",
       " 10899: 377,\n",
       " 10898: 377,\n",
       " 10952: 377,\n",
       " 10781: 304,\n",
       " 10890: 377,\n",
       " 10891: 377,\n",
       " 10951: 377,\n",
       " 10780: 299,\n",
       " 10779: 295,\n",
       " 10892: 377,\n",
       " 10893: 377,\n",
       " 10950: 377,\n",
       " 10761: 47,\n",
       " 10778: 286,\n",
       " 10894: 377,\n",
       " 10762: 51,\n",
       " 10895: 377,\n",
       " 10777: 268,\n",
       " 10896: 377,\n",
       " 10897: 377,\n",
       " 10911: 377,\n",
       " 10910: 377,\n",
       " 10938: 377,\n",
       " 10944: 377,\n",
       " 10769: 138,\n",
       " 10924: 377,\n",
       " 10925: 377,\n",
       " 10926: 377,\n",
       " 10766: 89,\n",
       " 10927: 377,\n",
       " 10928: 377,\n",
       " 10768: 124,\n",
       " 10929: 377,\n",
       " 10941: 377,\n",
       " 10930: 377,\n",
       " 10940: 377,\n",
       " 10931: 377,\n",
       " 10939: 377,\n",
       " 10932: 377,\n",
       " 10933: 377,\n",
       " 10934: 377,\n",
       " 10935: 377,\n",
       " 10936: 377,\n",
       " 10767: 106,\n",
       " 10765: 76,\n",
       " 10770: 154,\n",
       " 10912: 377,\n",
       " 10771: 170,\n",
       " 10913: 377,\n",
       " 10937: 377,\n",
       " 10775: 244,\n",
       " 10914: 377,\n",
       " 10915: 377,\n",
       " 10916: 377,\n",
       " 10917: 377,\n",
       " 10918: 377,\n",
       " 10774: 227,\n",
       " 10919: 377,\n",
       " 10943: 377,\n",
       " 10920: 377,\n",
       " 10921: 377,\n",
       " 10922: 377,\n",
       " 10773: 216,\n",
       " 10764: 71,\n",
       " 10942: 377,\n",
       " 10923: 377,\n",
       " 10772: 195,\n",
       " 10889: 377,\n",
       " 10813: 365,\n",
       " 10888: 377,\n",
       " 10832: 375,\n",
       " 10834: 376,\n",
       " 10804: 360,\n",
       " 10835: 376,\n",
       " 10803: 359,\n",
       " 10802: 357,\n",
       " 10836: 376,\n",
       " 10837: 376,\n",
       " 10838: 376,\n",
       " 10839: 376,\n",
       " 10801: 356,\n",
       " 10840: 376,\n",
       " 10841: 376,\n",
       " 10800: 356,\n",
       " 10842: 376,\n",
       " 10799: 355,\n",
       " 10843: 376,\n",
       " 10844: 376,\n",
       " 10845: 376,\n",
       " 10846: 376,\n",
       " 10847: 376,\n",
       " 10798: 355,\n",
       " 10848: 377,\n",
       " 10849: 377,\n",
       " 10833: 376,\n",
       " 10831: 374,\n",
       " 10782: 314,\n",
       " 10830: 374,\n",
       " 10815: 373,\n",
       " 10816: 372,\n",
       " 10812: 364,\n",
       " 10817: 375,\n",
       " 10811: 363,\n",
       " 10818: 373,\n",
       " 10819: 373,\n",
       " 10820: 374,\n",
       " 10810: 363,\n",
       " 10821: 374,\n",
       " 10809: 361,\n",
       " 10808: 361,\n",
       " 10822: 373,\n",
       " 10823: 373,\n",
       " 10807: 361,\n",
       " 10824: 373,\n",
       " 10825: 374,\n",
       " 10806: 361,\n",
       " 10826: 374,\n",
       " 10827: 374,\n",
       " 10828: 374,\n",
       " 10805: 361,\n",
       " 10829: 374,\n",
       " 10850: 377,\n",
       " 10851: 377,\n",
       " 10852: 377,\n",
       " 10853: 377,\n",
       " 10871: 377,\n",
       " 10872: 377,\n",
       " 10873: 377,\n",
       " 10789: 344,\n",
       " 10874: 377,\n",
       " 10875: 377,\n",
       " 10876: 377,\n",
       " 10788: 343,\n",
       " 10877: 377,\n",
       " 10878: 377,\n",
       " 10787: 341,\n",
       " 10786: 334,\n",
       " 10814: 372,\n",
       " 10879: 377,\n",
       " 10880: 377,\n",
       " 10881: 377,\n",
       " 10882: 377,\n",
       " 10883: 377,\n",
       " 10884: 377,\n",
       " 10784: 327,\n",
       " 10885: 377,\n",
       " 10886: 377,\n",
       " 10783: 323,\n",
       " 10870: 377,\n",
       " 10790: 346,\n",
       " 10791: 349,\n",
       " 10796: 357,\n",
       " 10953: 377,\n",
       " 10854: 377,\n",
       " 10855: 377,\n",
       " 10856: 377,\n",
       " 10857: 377,\n",
       " 10858: 377,\n",
       " 10859: 377,\n",
       " 10860: 377,\n",
       " 10797: 355,\n",
       " 10861: 377,\n",
       " 10862: 377,\n",
       " 10869: 377,\n",
       " 10795: 355,\n",
       " 10863: 377,\n",
       " 10864: 377,\n",
       " 10865: 377,\n",
       " 10794: 355,\n",
       " 10866: 377,\n",
       " 10867: 377,\n",
       " 10868: 377,\n",
       " 10793: 352,\n",
       " 10792: 351,\n",
       " 10785: 331,\n",
       " 10990: 377,\n",
       " 10954: 377,\n",
       " 11127: 377,\n",
       " 11114: 377,\n",
       " 11115: 377,\n",
       " 11116: 377,\n",
       " 11117: 377,\n",
       " 11118: 377,\n",
       " 11119: 377,\n",
       " 11120: 377,\n",
       " 11121: 377,\n",
       " 11122: 377,\n",
       " 11123: 377,\n",
       " 11124: 377,\n",
       " 11125: 377,\n",
       " 11126: 377,\n",
       " 11128: 377,\n",
       " 11081: 377,\n",
       " 11129: 377,\n",
       " 11130: 376,\n",
       " 11131: 377,\n",
       " 11132: 376,\n",
       " 11133: 376,\n",
       " 11134: 375,\n",
       " 11135: 375,\n",
       " 11136: 375,\n",
       " 11137: 375,\n",
       " 11138: 375,\n",
       " 11139: 375,\n",
       " 11140: 375,\n",
       " 11141: 375,\n",
       " 11113: 377,\n",
       " 11112: 377,\n",
       " 11111: 377,\n",
       " 11110: 377,\n",
       " 11083: 377,\n",
       " 11084: 377,\n",
       " 11085: 377,\n",
       " 11086: 377,\n",
       " 11087: 377,\n",
       " 11088: 377,\n",
       " 11089: 377,\n",
       " 11090: 377,\n",
       " 11091: 377,\n",
       " 11092: 377,\n",
       " 11093: 377,\n",
       " 11094: 377,\n",
       " 11095: 377,\n",
       " 11096: 377,\n",
       " 11097: 377,\n",
       " 11098: 377,\n",
       " 11099: 377,\n",
       " 11100: 377,\n",
       " 11101: 377,\n",
       " 11102: 377,\n",
       " 11103: 377,\n",
       " 11104: 377,\n",
       " 11105: 377,\n",
       " 11106: 377,\n",
       " 11107: 377,\n",
       " 11108: 377,\n",
       " 11109: 377,\n",
       " 11142: 375,\n",
       " 11143: 375,\n",
       " 11144: 375,\n",
       " 11175: 361,\n",
       " 11177: 359,\n",
       " 11178: 357,\n",
       " 11179: 355,\n",
       " 11180: 353,\n",
       " 11181: 349,\n",
       " 11182: 347,\n",
       " 11183: 344,\n",
       " 11184: 343,\n",
       " 11185: 342,\n",
       " 11186: 340,\n",
       " 11187: 338,\n",
       " 11188: 335,\n",
       " 11189: 331,\n",
       " 11190: 323,\n",
       " 11191: 315,\n",
       " 11192: 311,\n",
       " 11193: 308,\n",
       " 11194: 304,\n",
       " 11195: 297,\n",
       " 11196: 294,\n",
       " 11197: 290,\n",
       " 11198: 283,\n",
       " 11199: 277,\n",
       " 11200: 265,\n",
       " 11201: 257,\n",
       " 11202: 254,\n",
       " 11203: 242,\n",
       " 11176: 361,\n",
       " 11174: 362,\n",
       " 11145: 374,\n",
       " 11173: 362,\n",
       " 11146: 374,\n",
       " 11147: 374,\n",
       " 11148: 374,\n",
       " 11149: 374,\n",
       " 11150: 374,\n",
       " 11151: 374,\n",
       " 11152: 373,\n",
       " 11153: 373,\n",
       " 11154: 373,\n",
       " 11155: 373,\n",
       " 11156: 373,\n",
       " 11157: 373,\n",
       " 11158: 373,\n",
       " 11159: 373,\n",
       " 11160: 373,\n",
       " 11161: 373,\n",
       " 11162: 373,\n",
       " 11163: 373,\n",
       " 11164: 373,\n",
       " 11165: 373,\n",
       " 11166: 373,\n",
       " 11167: 374,\n",
       " 11168: 372,\n",
       " 11169: 365,\n",
       " 11170: 365,\n",
       " 11171: 365,\n",
       " 11172: 364,\n",
       " 11082: 377,\n",
       " 11080: 377,\n",
       " 10955: 377,\n",
       " 11002: 377,\n",
       " 10988: 377,\n",
       " 10989: 377,\n",
       " 10759: 41,\n",
       " 10991: 377,\n",
       " 10992: 377,\n",
       " 10993: 377,\n",
       " 10994: 377,\n",
       " 10996: 377,\n",
       " 10997: 377,\n",
       " 10998: 377,\n",
       " 10999: 377,\n",
       " 11000: 377,\n",
       " 11001: 377,\n",
       " 11003: 377,\n",
       " 11079: 377,\n",
       " 11004: 377,\n",
       " 11005: 377,\n",
       " 11006: 377,\n",
       " 11007: 377,\n",
       " 11008: 377,\n",
       " 11009: 377,\n",
       " 11010: 377,\n",
       " 11011: 377,\n",
       " 11012: 377,\n",
       " 11013: 377,\n",
       " 11014: 377,\n",
       " 11015: 377,\n",
       " 11016: 377,\n",
       " 10987: 377,\n",
       " 10986: 377,\n",
       " 10985: 377,\n",
       " 10984: 377,\n",
       " 10956: 377,\n",
       " 10957: 377,\n",
       " 10958: 377,\n",
       " 10959: 377,\n",
       " 10960: 377,\n",
       " 10961: 377,\n",
       " 10962: 377,\n",
       " 10963: 377,\n",
       " 10964: 377,\n",
       " 10965: 377,\n",
       " 10966: 377,\n",
       " 10967: 377,\n",
       " 10968: 377,\n",
       " 10969: 377,\n",
       " 10970: 377,\n",
       " 10971: 377,\n",
       " 10972: 377,\n",
       " 10973: 377,\n",
       " 10974: 377,\n",
       " 10975: 377,\n",
       " 10976: 377,\n",
       " 10977: 377,\n",
       " 10978: 377,\n",
       " 10979: 377,\n",
       " 10980: 377,\n",
       " 10981: 377,\n",
       " 10982: 377,\n",
       " 11017: 377,\n",
       " 11018: 377,\n",
       " 11019: 377,\n",
       " 11050: 377,\n",
       " 11052: 377,\n",
       " 11053: 377,\n",
       " 11054: 377,\n",
       " 11055: 377,\n",
       " 11056: 377,\n",
       " 11057: 377,\n",
       " 11058: 377,\n",
       " 11059: 377,\n",
       " 11060: 377,\n",
       " 11061: 377,\n",
       " 11062: 377,\n",
       " 11063: 377,\n",
       " 11064: 377,\n",
       " 11065: 377,\n",
       " 11066: 377,\n",
       " 11067: 377,\n",
       " 11068: 377,\n",
       " 11069: 377,\n",
       " 11070: 377,\n",
       " 11071: 377,\n",
       " 11072: 377,\n",
       " 11073: 377,\n",
       " 11074: 377,\n",
       " 11075: 377,\n",
       " 11076: 377,\n",
       " 11077: 377,\n",
       " 11078: 377,\n",
       " 11051: 377,\n",
       " 11049: 377,\n",
       " 11020: 377,\n",
       " 11048: 377,\n",
       " 11021: 377,\n",
       " 11022: 377,\n",
       " 11023: 377,\n",
       " 11024: 377,\n",
       " 11025: 377,\n",
       " 11026: 377,\n",
       " 11027: 377,\n",
       " 11028: 377,\n",
       " 11029: 377,\n",
       " 11030: 377,\n",
       " 11031: 377,\n",
       " 11032: 377,\n",
       " 11033: 377,\n",
       " 11034: 377,\n",
       " 11035: 377,\n",
       " 11036: 377,\n",
       " 11037: 377,\n",
       " 11038: 377,\n",
       " 11039: 377,\n",
       " 11040: 377,\n",
       " 11041: 377,\n",
       " 11042: 377,\n",
       " 11043: 377,\n",
       " 11044: 377,\n",
       " 11045: 377,\n",
       " 11046: 377,\n",
       " 11047: 377,\n",
       " 10760: 45,\n",
       " 10719: 7,\n",
       " 10758: 35,\n",
       " 10426: 351,\n",
       " 10413: 347,\n",
       " 10414: 349,\n",
       " 10415: 348,\n",
       " 10416: 348,\n",
       " 10417: 347,\n",
       " 10418: 348,\n",
       " 10419: 350,\n",
       " 10420: 350,\n",
       " 10421: 351,\n",
       " 10422: 351,\n",
       " 10423: 351,\n",
       " 10424: 350,\n",
       " 10425: 351,\n",
       " 10427: 359,\n",
       " 10442: 351,\n",
       " 10428: 351,\n",
       " 10429: 350,\n",
       " 10430: 351,\n",
       " 10431: 351,\n",
       " 10432: 352,\n",
       " 10433: 353,\n",
       " 10434: 355,\n",
       " 10435: 353,\n",
       " 10436: 354,\n",
       " 10437: 351,\n",
       " 10438: 350,\n",
       " 10439: 350,\n",
       " 10440: 350,\n",
       " 10412: 348,\n",
       " 10411: 348,\n",
       " 10410: 348,\n",
       " 10409: 350,\n",
       " 10382: 155,\n",
       " 10383: 155,\n",
       " 10384: 158,\n",
       " 10385: 164,\n",
       " 10386: 184,\n",
       " 10387: 195,\n",
       " 10388: 213,\n",
       " 10389: 224,\n",
       " 10390: 235,\n",
       " 10391: 258,\n",
       " 10392: 272,\n",
       " 10393: 282,\n",
       " 10394: 284,\n",
       " 10395: 290,\n",
       " 10396: 300,\n",
       " 10397: 314,\n",
       " 10398: 323,\n",
       " 10399: 338,\n",
       " 10400: 342,\n",
       " 10401: 345,\n",
       " 10402: 349,\n",
       " 10403: 350,\n",
       " 10404: 348,\n",
       " 10405: 350,\n",
       " 10406: 350,\n",
       " 10407: 352,\n",
       " 10408: 352,\n",
       " 10441: 349,\n",
       " 10443: 349,\n",
       " 10505: 336,\n",
       " 10489: 356,\n",
       " 10476: 354,\n",
       " 10477: 355,\n",
       " 10478: 355,\n",
       " 10479: 355,\n",
       " 10480: 355,\n",
       " 10481: 357,\n",
       " 10482: 356,\n",
       " 10483: 356,\n",
       " 10484: 356,\n",
       " 10485: 356,\n",
       " 10486: 356,\n",
       " 10487: 356,\n",
       " 10488: 356,\n",
       " 10490: 357,\n",
       " 10444: 347,\n",
       " 10491: 356,\n",
       " 10492: 356,\n",
       " 10493: 357,\n",
       " 10494: 357,\n",
       " 10495: 357,\n",
       " 10496: 356,\n",
       " 10497: 357,\n",
       " 10498: 356,\n",
       " 10499: 354,\n",
       " 10500: 353,\n",
       " 10501: 343,\n",
       " 10502: 336,\n",
       " 10503: 334,\n",
       " 10475: 355,\n",
       " 10474: 354,\n",
       " 10473: 353,\n",
       " 10472: 353,\n",
       " 10445: 348,\n",
       " 10446: 350,\n",
       " 10447: 349,\n",
       " 10448: 349,\n",
       " 10449: 350,\n",
       " 10450: 350,\n",
       " 10451: 353,\n",
       " 10452: 357,\n",
       " 10453: 358,\n",
       " 10454: 352,\n",
       " 10455: 353,\n",
       " 10456: 351,\n",
       " 10457: 351,\n",
       " 10458: 351,\n",
       " 10459: 351,\n",
       " 10460: 350,\n",
       " 10461: 350,\n",
       " 10462: 352,\n",
       " 10463: 352,\n",
       " 10464: 352,\n",
       " 10465: 352,\n",
       " 10466: 352,\n",
       " 10467: 352,\n",
       " 10468: 352,\n",
       " 10469: 352,\n",
       " 10470: 353,\n",
       " 10471: 353,\n",
       " 10381: 175,\n",
       " 10380: 174,\n",
       " 10379: 160,\n",
       " 10301: 321,\n",
       " 10288: 315,\n",
       " 10289: 322,\n",
       " 10290: 315,\n",
       " 10291: 314,\n",
       " 10292: 316,\n",
       " 10293: 309,\n",
       " 10294: 311,\n",
       " 10295: 309,\n",
       " 10296: 309,\n",
       " 10297: 309,\n",
       " 10298: 308,\n",
       " 10299: 312,\n",
       " 10300: 316,\n",
       " 10302: 327,\n",
       " 10378: 168,\n",
       " 10303: 334,\n",
       " 10304: 341,\n",
       " 10305: 343,\n",
       " 10306: 346,\n",
       " 10307: 346,\n",
       " 10308: 350,\n",
       " 10309: 352,\n",
       " 10310: 351,\n",
       " 10311: 353,\n",
       " 10312: 353,\n",
       " 10313: 355,\n",
       " 10314: 356,\n",
       " 10315: 361,\n",
       " 10287: 321,\n",
       " 10286: 321,\n",
       " 10285: 321,\n",
       " 10284: 323,\n",
       " 10256: 69,\n",
       " 10257: 78,\n",
       " 10258: 94,\n",
       " 10259: 109,\n",
       " 10261: 135,\n",
       " 10262: 156,\n",
       " 10263: 167,\n",
       " 10264: 183,\n",
       " 10265: 201,\n",
       " 10266: 214,\n",
       " 10267: 231,\n",
       " 10268: 244,\n",
       " 10269: 251,\n",
       " 10270: 267,\n",
       " 10271: 278,\n",
       " 10272: 294,\n",
       " 10273: 298,\n",
       " 10274: 304,\n",
       " 10275: 313,\n",
       " 10276: 321,\n",
       " 10277: 325,\n",
       " 10278: 330,\n",
       " 10279: 332,\n",
       " 10280: 335,\n",
       " 10281: 328,\n",
       " 10282: 328,\n",
       " 10283: 325,\n",
       " 10316: 362,\n",
       " 10317: 360,\n",
       " 10318: 357,\n",
       " 10349: 74,\n",
       " 10351: 95,\n",
       " 10352: 110,\n",
       " 10353: 109,\n",
       " 10354: 121,\n",
       " 10355: 130,\n",
       " 10356: 142,\n",
       " 10357: 153,\n",
       " 10358: 174,\n",
       " 10359: 183,\n",
       " 10360: 194,\n",
       " 10361: 202,\n",
       " 10362: 203,\n",
       " 10363: 204,\n",
       " 10364: 209,\n",
       " 10365: 214,\n",
       " 6110: 3,\n",
       " 10697: 38,\n",
       " 6884: 31,\n",
       " 28680: 68,\n",
       " 20172: 8,\n",
       " 17731: 6,\n",
       " 29243: 204,\n",
       " 18128: 4,\n",
       " 20309: 19,\n",
       " 6750: 18,\n",
       " 16264: 6,\n",
       " 24076: 10,\n",
       " 16187: 4,\n",
       " 13511: 5,\n",
       " 28968: 18,\n",
       " 5920: 14,\n",
       " 31841: 28,\n",
       " 9974: 1,\n",
       " 40: 17,\n",
       " 24390: 12,\n",
       " 14957: 14,\n",
       " 29164: 5,\n",
       " 20562: 40,\n",
       " 15526: 67,\n",
       " 2292: 5,\n",
       " 12957: 10,\n",
       " 1932: 18,\n",
       " 23749: 2,\n",
       " 12991: 6,\n",
       " 16506: 16,\n",
       " 20997: 8,\n",
       " 21297: 15,\n",
       " 7803: 32,\n",
       " 15838: 36,\n",
       " 395: 4,\n",
       " 11764: 36,\n",
       " 1926: 7,\n",
       " 28854: 19,\n",
       " 22616: 24,\n",
       " 3324: 9,\n",
       " 8727: 31,\n",
       " 25663: 14,\n",
       " 14497: 2,\n",
       " 15104: 6,\n",
       " 26767: 10,\n",
       " 310: 43,\n",
       " 18574: 23,\n",
       " 12319: 9,\n",
       " 26945: 19,\n",
       " 1976: 4,\n",
       " 17804: 2,\n",
       " 1634: 27,\n",
       " 31056: 10,\n",
       " 25655: 11,\n",
       " 26318: 24,\n",
       " 20438: 12,\n",
       " 3881: 41,\n",
       " 12902: 30,\n",
       " 10740: 53,\n",
       " 20847: 28,\n",
       " 19176: 12,\n",
       " 12828: 32,\n",
       " 6185: 46,\n",
       " 29714: 16,\n",
       " 32034: 21,\n",
       " 18025: 6,\n",
       " 17730: 21,\n",
       " 13837: 21,\n",
       " 26004: 13,\n",
       " 17745: 28,\n",
       " 722: 14,\n",
       " 14821: 27,\n",
       " 5670: 6,\n",
       " 4340: 16,\n",
       " 15418: 12,\n",
       " 5298: 23,\n",
       " 24496: 11,\n",
       " 14279: 28,\n",
       " 26697: 20,\n",
       " 23205: 5,\n",
       " 13365: 36,\n",
       " 18028: 14,\n",
       " 12986: 14,\n",
       " 4492: 24,\n",
       " 24968: 21,\n",
       " 4541: 8,\n",
       " 23422: 21,\n",
       " 24161: 6,\n",
       " 23648: 2,\n",
       " 31958: 14,\n",
       " 29041: 16,\n",
       " 28405: 47,\n",
       " 22155: 9,\n",
       " 2359: 7,\n",
       " 12972: 14,\n",
       " 521: 30,\n",
       " 31438: 20,\n",
       " 28782: 11,\n",
       " 17872: 13,\n",
       " 17087: 29,\n",
       " 18253: 6,\n",
       " 31486: 9,\n",
       " 17392: 12,\n",
       " 26353: 21,\n",
       " 1148: 35,\n",
       " 5848: 13,\n",
       " 16657: 13,\n",
       " 26042: 17,\n",
       " 26254: 2,\n",
       " 7126: 6,\n",
       " 12649: 13,\n",
       " 9395: 4,\n",
       " 28617: 19,\n",
       " 4623: 27,\n",
       " 21021: 2,\n",
       " 29482: 17,\n",
       " 607: 22,\n",
       " 22419: 14,\n",
       " 17305: 23,\n",
       " 9168: 26,\n",
       " 8217: 27,\n",
       " 25771: 6,\n",
       " 30497: 30,\n",
       " 18151: 8,\n",
       " 20570: 8,\n",
       " 1339: 27,\n",
       " 28331: 16,\n",
       " 16070: 10,\n",
       " 9241: 3,\n",
       " 10114: 14,\n",
       " 30503: 14,\n",
       " 21666: 14,\n",
       " 44: 14,\n",
       " 7339: 1,\n",
       " 12530: 18,\n",
       " 21700: 12,\n",
       " 19711: 30,\n",
       " 9657: 2,\n",
       " 19788: 8,\n",
       " 13006: 25,\n",
       " 30102: 16,\n",
       " 32517: 5,\n",
       " 26870: 5,\n",
       " 15244: 5,\n",
       " 930: 17,\n",
       " 12871: 10,\n",
       " 12053: 12,\n",
       " 29543: 5,\n",
       " 26408: 20,\n",
       " 4510: 12,\n",
       " 26643: 24,\n",
       " 20687: 8,\n",
       " 15943: 99,\n",
       " 30911: 17,\n",
       " 23506: 12,\n",
       " 20198: 6,\n",
       " 32767: 284,\n",
       " 10504: 326,\n",
       " 10506: 315,\n",
       " 10507: 314,\n",
       " 10508: 301,\n",
       " 10509: 288,\n",
       " 10510: 279,\n",
       " 10511: 263,\n",
       " 10512: 254,\n",
       " 10514: 219,\n",
       " 10322: 307,\n",
       " 10319: 347,\n",
       " 10320: 339,\n",
       " 30903: 4,\n",
       " 11224: 74,\n",
       " 6188: 1,\n",
       " 19964: 10,\n",
       " 19540: 3,\n",
       " 8480: 57,\n",
       " 9212: 24,\n",
       " 29774: 24,\n",
       " 13804: 6,\n",
       " 27518: 8,\n",
       " 18695: 17,\n",
       " 21319: 17,\n",
       " 10571: 31,\n",
       " 7508: 13,\n",
       " 9259: 15,\n",
       " 23057: 7,\n",
       " 29587: 2,\n",
       " 9107: 11,\n",
       " 16414: 30,\n",
       " 22700: 4,\n",
       " 23163: 5,\n",
       " 26311: 20,\n",
       " 28123: 16,\n",
       " 22450: 8,\n",
       " 12571: 10,\n",
       " 27474: 16,\n",
       " 19713: 5,\n",
       " 8729: 9,\n",
       " 31150: 2,\n",
       " 29350: 17,\n",
       " 14298: 18,\n",
       " ...}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Analyze which features activate for specific tokens\n",
    "# top_n = 800  \n",
    "# top_features = []\n",
    "\n",
    "# for sentence_idx, per_token_features in enumerate(sparse_representations):\n",
    "#     sentence_top_features = []\n",
    "    \n",
    "#     for token_idx, features in enumerate(per_token_features):\n",
    "#         # Extract top N active features for this token\n",
    "#         top_indices = np.argsort(features)[-top_n:][::-1]\n",
    "#         sentence_top_features.append(set(top_indices))\n",
    "    \n",
    "#     top_features.append(sentence_top_features)  # Store per-token top feature indices\n",
    "\n",
    "# # Example: Print feature activations for each token in the first sentence\n",
    "# tokenized_sentence = tokenizer(sentences[0])['input_ids']\n",
    "# decoded_tokens = tokenizer.convert_ids_to_tokens(tokenized_sentence)\n",
    "\n",
    "# print(\"\\nFeature activations for the first sentence:\")\n",
    "# for token, feature_set in zip(decoded_tokens, top_features[0]):\n",
    "#     print(f\"Token: {token}, Top Features: {list(feature_set)[:10]}\")  # Show top 5 features\n",
    "\n",
    "#     # Example: Print feature activations for each token in the first sentence\n",
    "# tokenized_sentence = tokenizer(sentences[1])['input_ids']\n",
    "# decoded_tokens = tokenizer.convert_ids_to_tokens(tokenized_sentence)\n",
    "\n",
    "# print(\"\\nFeature activations for the first sentence:\")\n",
    "# for token, feature_set in zip(decoded_tokens, top_features[0]):\n",
    "#     print(f\"Token: {token}, Top Features: {list(feature_set)[:10]}\")  # Show top 5 features\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the most frequently occurring features\n",
    "top_common_features = sorted(feature_counts, key=feature_counts.get, reverse=True)[:800]\n",
    "\n",
    "# Create a synthetic sparse vector using these common features\n",
    "synthetic_sparse_vector = np.zeros((32768,))  # Assume dictionary size is 32768\n",
    "for idx in top_common_features:\n",
    "    synthetic_sparse_vector[idx] = 1  # Set these features as active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode sparse vector back into model space\n",
    "synthetic_dense_vector = ae.decode(torch.tensor(synthetic_sparse_vector).float()).detach().cpu()\n",
    "synthetic_dense_vector *= 10  # Experiment with scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized input: ['Do', 'Ġyou', 'Ġprefer', 'Ġthe', 'Ġcolor', 'Ġred', 'Ġor', 'Ġblue', '?', 'ĠI', 'Ġprefer', 'Ġthe', 'Ġcolor']\n"
     ]
    }
   ],
   "source": [
    "# Add a new special token\n",
    "\n",
    "masked_sentence = \"Do you prefer the color red or blue? I prefer the color\"\n",
    "input_ids = tokenizer(masked_sentence, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "# Convert token IDs to tokens\n",
    "decoded_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "print(f\"Tokenized input: {decoded_tokens}\")  # Debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4797,  2502,  4759,   273, 13735,  8862, 14863,  3168,  2806, 11978]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' blue',\n",
       " ' red',\n",
       " ' green',\n",
       " ' of',\n",
       " ' orange',\n",
       " ' yellow',\n",
       " ' pink',\n",
       " ' white',\n",
       " ' black',\n",
       " ' gray']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Convert input_ids to embeddings\n",
    "model_inputs = model.get_input_embeddings()(input_ids)\n",
    "\n",
    "# Inject synthetic feature vector at the placeholder position\n",
    "# model_inputs[:, placeholder_index, :] = synthetic_dense_vector\n",
    "# Even without injection returns a filler word; e.g., \"the\"\n",
    "\n",
    "# Generate text from modified embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs_embeds=model_inputs)\n",
    "    logits = outputs.logits[:, -1, :]  # Get last token logits\n",
    "    logs, tokens = torch.topk(logits, 10,dim=-1)\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "# Decode the predicted token\n",
    "predicted_words = tokenizer.batch_decode([token.item() for token in tokens[0]])\n",
    "\n",
    "predicted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
