{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from dictionary import AutoEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The capital of Russia is Moscow.', 'The capital of China is Beijing.', 'The capital of Greece is Athens.', 'The capital of Germany is Berlin.', 'The capital of France is Paris.', 'The capital of the United Kingdom is London.', 'The capital of Japan is Tokyo.', 'The capital of Egypt is Cairo.', 'The capital of Italy is Rome.', 'The capital of Spain is Madrid.', 'The capital of Portugal is Lisbon.', 'The capital of Canada is Ottawa.', 'The capital of Australia is Canberra.', 'The capital of Brazil is Brasília.', 'The capital of India is New Delhi.', 'The capital of the United States is Washington, D.C.', 'The capital of Argentina is Buenos Aires.', 'The capital of Mexico is Mexico City.', 'The capital of South Korea is Seoul.', 'The capital of Indonesia is Jakarta.', 'The capital of Thailand is Bangkok.', 'The capital of Norway is Oslo.', 'The capital of Sweden is Stockholm.', 'The capital of Finland is Helsinki.', 'The capital of Poland is Warsaw.', 'The capital of Austria is Vienna.']\n"
     ]
    }
   ],
   "source": [
    "# Load sentences from CSV file\n",
    "df = pd.read_csv(\"sentences.csv\", delimiter=\",\", encoding=\"utf-8\", quotechar='\"')\n",
    "sentences = df['sentence'].tolist()\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `GPTNeoXSdpaAttention` class is deprecated in favor of simply modifying the `config._attn_implementation`attribute of the `GPTNeoXAttention` class! It will be removed in v4.48\n"
     ]
    }
   ],
   "source": [
    "# Load the Pythia model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m-deduped\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m-deduped\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized output: ['The', 'Ġcapital', 'Ġof', 'ĠRussia', 'Ġis', 'ĠMoscow', '.', 'ĠMoscow', 'Ġis', 'Ġin', 'ĠRussia', '.']\n"
     ]
    }
   ],
   "source": [
    "# Testing tokenizer \n",
    "sentence = \"The capital of Russia is Moscow. Moscow is in Russia.\"\n",
    "tokenized_sentence = tokenizer(sentence)['input_ids']\n",
    "decoded_tokens = tokenizer.convert_ids_to_tokens(tokenized_sentence)\n",
    "\n",
    "print(\"Tokenized output:\", decoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_list = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    \"\"\"Hook function to capture activations from the 4th MLP layer.\"\"\"\n",
    "    activation_list.append(output)\n",
    "\n",
    "# Hook 4th MLP layer (index 3)\n",
    "layer_to_hook = model.gpt_neox.layers[5].mlp\n",
    "hook = layer_to_hook.register_forward_hook(hook_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 'The capital of Russia is Moscow.'\n",
      "\n",
      "Processing: 'The capital of China is Beijing.'\n",
      "\n",
      "Processing: 'The capital of Greece is Athens.'\n",
      "\n",
      "Processing: 'The capital of Germany is Berlin.'\n",
      "\n",
      "Processing: 'The capital of France is Paris.'\n",
      "\n",
      "Processing: 'The capital of the United Kingdom is London.'\n",
      "\n",
      "Processing: 'The capital of Japan is Tokyo.'\n",
      "\n",
      "Processing: 'The capital of Egypt is Cairo.'\n",
      "\n",
      "Processing: 'The capital of Italy is Rome.'\n",
      "\n",
      "Processing: 'The capital of Spain is Madrid.'\n",
      "\n",
      "Processing: 'The capital of Portugal is Lisbon.'\n",
      "\n",
      "Processing: 'The capital of Canada is Ottawa.'\n",
      "\n",
      "Processing: 'The capital of Australia is Canberra.'\n",
      "\n",
      "Processing: 'The capital of Brazil is Brasília.'\n",
      "\n",
      "Processing: 'The capital of India is New Delhi.'\n",
      "\n",
      "Processing: 'The capital of the United States is Washington, D.C.'\n",
      "\n",
      "Processing: 'The capital of Argentina is Buenos Aires.'\n",
      "\n",
      "Processing: 'The capital of Mexico is Mexico City.'\n",
      "\n",
      "Processing: 'The capital of South Korea is Seoul.'\n",
      "\n",
      "Processing: 'The capital of Indonesia is Jakarta.'\n",
      "\n",
      "Processing: 'The capital of Thailand is Bangkok.'\n",
      "\n",
      "Processing: 'The capital of Norway is Oslo.'\n",
      "\n",
      "Processing: 'The capital of Sweden is Stockholm.'\n",
      "\n",
      "Processing: 'The capital of Finland is Helsinki.'\n",
      "\n",
      "Processing: 'The capital of Poland is Warsaw.'\n",
      "\n",
      "Processing: 'The capital of Austria is Vienna.'\n",
      "Captured activations for 26 sentences.\n"
     ]
    }
   ],
   "source": [
    "# Store per-token activations\n",
    "individual_activations = []\n",
    "    \n",
    "for sentence in sentences:\n",
    "    print(f\"\\nProcessing: '{sentence}'\")\n",
    "    input_ids_batch = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    model(**input_ids_batch)  # Forward pass to capture activations\n",
    "\n",
    "    if activation_list:\n",
    "        activations = activation_list[-1].squeeze(0)  # Shape: (seq_len, hidden_dim)\n",
    "        individual_activations.append(activations)\n",
    "    activation_list.clear()\n",
    "\n",
    "print(f\"Captured activations for {len(individual_activations)} sentences.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dictionary Learning AutoEncoder\n",
    "ae = AutoEncoder.from_pretrained(\n",
    "    \"dictionaries/pythia-70m-deduped/mlp_out_layer5/10_32768/ae.pt\", \n",
    "    map_location=torch.device('cpu')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 26 sentences into token-aligned sparse representations.\n"
     ]
    }
   ],
   "source": [
    "# Convert activations to sparse representations\n",
    "sparse_representations = []\n",
    "for activations in individual_activations:\n",
    "    sparse_repr = ae.encode(activations).detach().cpu().numpy()  # (seq_len, dict_size)\n",
    "    sparse_representations.append(sparse_repr)\n",
    "print(f\"Processed {len(sparse_representations)} sentences into token-aligned sparse representations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate features: Find top activated features across all tokens in all sentences\n",
    "feature_counts = {}\n",
    "for sentence_features in sparse_representations:\n",
    "    for token_features in sentence_features:\n",
    "        top_indices = np.argsort(token_features)[-3:][::-1]  # Top 800 features per token\n",
    "        for idx in top_indices:\n",
    "            feature_counts[idx] = feature_counts.get(idx, 0) + 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(array([3., 2., 1., 3., 0., 1., 2., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 1.]), array([0.42556709, 0.46641603, 0.50726497, 0.54811388, 0.58896279,\n",
      "       0.62981176, 0.67066067, 0.71150959, 0.75235856, 0.79320753,\n",
      "       0.83405644, 0.87490535, 0.91575432, 0.95660323, 0.99745214,\n",
      "       1.03830111, 1.07914996, 1.11999893, 1.1608479 , 1.20169687,\n",
      "       1.24254584, 1.28339469, 1.32424355, 1.36509252, 1.40594149,\n",
      "       1.44679034]), <BarContainer object of 25 artists>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_ind = 3\n",
    "\n",
    "coeffs = []\n",
    "\n",
    "for sentence_features in sparse_representations:\n",
    "    for i, token_features in enumerate(sentence_features):\n",
    "        top_indices = np.argsort(token_features)[-15:][::-1]  # Top 800 features per token\n",
    "        coeffs.append([token_features[top_indices[j]] for j in range(len(top_indices))])\n",
    "\n",
    "print()\n",
    "print(plt.hist(coeffs[token_ind], bins=25))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Analyze which features activate for specific tokens\n",
    "# top_n = 800  \n",
    "# top_features = []\n",
    "\n",
    "# for sentence_idx, per_token_features in enumerate(sparse_representations):\n",
    "#     sentence_top_features = []\n",
    "    \n",
    "#     for token_idx, features in enumerate(per_token_features):\n",
    "#         # Extract top N active features for this token\n",
    "#         top_indices = np.argsort(features)[-top_n:][::-1]\n",
    "#         sentence_top_features.append(set(top_indices))\n",
    "    \n",
    "#     top_features.append(sentence_top_features)  # Store per-token top feature indices\n",
    "\n",
    "# # Example: Print feature activations for each token in the first sentence\n",
    "# tokenized_sentence = tokenizer(sentences[0])['input_ids']\n",
    "# decoded_tokens = tokenizer.convert_ids_to_tokens(tokenized_sentence)\n",
    "\n",
    "# print(\"\\nFeature activations for the first sentence:\")\n",
    "# for token, feature_set in zip(decoded_tokens, top_features[0]):\n",
    "#     print(f\"Token: {token}, Top Features: {list(feature_set)[:10]}\")  # Show top 5 features\n",
    "\n",
    "#     # Example: Print feature activations for each token in the first sentence\n",
    "# tokenized_sentence = tokenizer(sentences[1])['input_ids']\n",
    "# decoded_tokens = tokenizer.convert_ids_to_tokens(tokenized_sentence)\n",
    "\n",
    "# print(\"\\nFeature activations for the first sentence:\")\n",
    "# for token, feature_set in zip(decoded_tokens, top_features[0]):\n",
    "#     print(f\"Token: {token}, Top Features: {list(feature_set)[:10]}\")  # Show top 5 features\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the most frequently occurring features\n",
    "top_common_features = sorted(feature_counts, key=feature_counts.get, reverse=True)[:3]\n",
    "\n",
    "# Create a synthetic sparse vector using these common features\n",
    "synthetic_sparse_vector = np.zeros((32768,))  # Assume dictionary size is 32768\n",
    "for idx in top_common_features:\n",
    "    synthetic_sparse_vector[idx] = 1  # Set these features as active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode sparse vector back into model space\n",
    "synthetic_dense_vector = ae.decode(torch.tensor(synthetic_sparse_vector).float()).detach().cpu()\n",
    "synthetic_dense_vector *= 0.1  # Experiment with scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized input: ['The', 'Ġcapital', 'Ġof', 'Ġ', '<XYZ>', 'Ġis']\n"
     ]
    }
   ],
   "source": [
    "# Add a new special token\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': [\"<XYZ>\"]})\n",
    "model.resize_token_embeddings(len(tokenizer))  # Resize embeddings to include new token\n",
    "\n",
    "masked_sentence = \"The capital of <XYZ> is\"\n",
    "input_ids = tokenizer(masked_sentence, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "# Convert token IDs to tokens\n",
    "decoded_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "print(f\"Tokenized input: {decoded_tokens}\")  # Debugging\n",
    "\n",
    "# **Find the placeholder index**\n",
    "try:\n",
    "    placeholder_index = decoded_tokens.index(\"<XYZ>\")\n",
    "except ValueError:\n",
    "    raise ValueError(f\"Could not find placeholder token in: {decoded_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted token:  the\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert input_ids to embeddings\n",
    "model_inputs = model.get_input_embeddings()(input_ids)\n",
    "\n",
    "# Inject synthetic feature vector at the placeholder position\n",
    "model_inputs[:, placeholder_index, :] = synthetic_dense_vector\n",
    "\n",
    "# Generate text from modified embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs_embeds=model_inputs)\n",
    "    logits = outputs.logits[:, -1, :]  # Get last token logits\n",
    "    predicted_token_id = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "# Decode the predicted token\n",
    "predicted_word = tokenizer.decode([predicted_token_id])\n",
    "\n",
    "print(f\"Predicted token: {predicted_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the', ' the']\n"
     ]
    }
   ],
   "source": [
    "num_predictions = 100\n",
    "prediction = []\n",
    "\n",
    "\n",
    "for _ in range(num_predictions):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs_embeds=model_inputs)\n",
    "        logits = outputs.logits[:, -1, :]  # Get last token logits\n",
    "        predicted_token_id = torch.argmax(logits, dim=-1).item()\n",
    "    prediction.append(tokenizer.decode([predicted_token_id]))\n",
    "\n",
    "\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
