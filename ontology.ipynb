{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:12.818910Z",
     "start_time": "2025-04-01T22:32:10.135539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import cell\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import k_means\n",
    "from clustering import Pythia_model\n",
    "import pickle\n",
    "import joblib"
   ],
   "id": "baecc3dbe611dfcb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sv-goat/dictionary_learning/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:12.826178Z",
     "start_time": "2025-04-01T22:32:12.823097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read the JSON file, get the key terms into correct a list\n",
    "data = json.loads(open('mesh_terms.json').read())"
   ],
   "id": "a6ed1621831207b8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:12.881914Z",
     "start_time": "2025-04-01T22:32:12.879741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parents = list(data.keys()) #data.keys()\n",
    "print(parents)"
   ],
   "id": "e3a632b2930aba70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anatomy', 'Diseases', 'Chemicals and Drugs', 'Phenomena and Processes']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:12.931883Z",
     "start_time": "2025-04-01T22:32:12.927884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the children of each parent\n",
    "children = []\n",
    "for parent in parents:\n",
    "    children.append(list(data[parent].keys()))\n",
    "print(children)"
   ],
   "id": "b3768ba1844753b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Extremities', 'Cartilage', 'Liver', 'Lung'], ['Infections', 'Cysts', 'Arm Injuries', 'Drowning'], ['Organic Chemicals', 'Micelles', 'Carbohydrates', 'Biological Factors'], ['Physical Phenomena', 'Metabolism', 'Algorithms', 'Fourier Analysis']]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:12.981457Z",
     "start_time": "2025-04-01T22:32:12.978733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_terms = []\n",
    "for parent in parents:\n",
    "    all_terms.append(parent)\n",
    "for child in children:\n",
    "    all_terms.extend(child)\n",
    "print(all_terms)"
   ],
   "id": "cb3ec2baab01c1e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anatomy', 'Diseases', 'Chemicals and Drugs', 'Phenomena and Processes', 'Extremities', 'Cartilage', 'Liver', 'Lung', 'Infections', 'Cysts', 'Arm Injuries', 'Drowning', 'Organic Chemicals', 'Micelles', 'Carbohydrates', 'Biological Factors', 'Physical Phenomena', 'Metabolism', 'Algorithms', 'Fourier Analysis']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:13.036845Z",
     "start_time": "2025-04-01T22:32:13.033528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### USE IF YOU WANNA INITIALIZE A DATASET WITH DIFFERENT PARAMETERS\n",
    "\n",
    "# # Extract sentences from the Pile dataset that have these terms.\n",
    "# pile_dataset = load_dataset(\"monology/pile-uncopyrighted\", split=\"train\", streaming=True)\n",
    "# sentences_per_term = [0 for i in range(len(all_terms))]\n",
    "# num_sentences = 0\n",
    "# biomedical_sentences = [[] for i in range(len(all_terms))]\n",
    "# for sentence in pile_dataset:\n",
    "#     for i, term in enumerate(all_terms):\n",
    "#         # Convert to lower case\n",
    "#         term = term.lower()\n",
    "#         if term in sentence[\"text\"] and sentences_per_term[i] < 60:\n",
    "#             sentences_per_term[i] += 1\n",
    "#             biomedical_sentences[i].append(sentence[\"text\"])\n",
    "#             num_sentences += 1\n",
    "#             break\n",
    "#     if num_sentences >= 1000:\n",
    "#         break"
   ],
   "id": "5f1ccc68e87dc87e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:13.080782Z",
     "start_time": "2025-04-01T22:32:13.076766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### UTIL BLOCK IF WE NEED TO DO IT FROM SCRATCH\n",
    "\n",
    "\n",
    "# # Convert sentences into a dataframe\n",
    "# df = pd.DataFrame()\n",
    "# df['Term'] = []\n",
    "# df['Sentence'] = []\n",
    "# count = 0\n",
    "# for i, term in enumerate(all_terms):\n",
    "#     for sentence in biomedical_sentences[i]:\n",
    "#         df.loc[count] =  [term, sentence]\n",
    "#         count += 1\n",
    "# # Save it\n",
    "# df.to_csv(\"biomedical_sentences.csv\")\n",
    "#\n"
   ],
   "id": "ee3fc7b8ff4db5aa",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:13.319539Z",
     "start_time": "2025-04-01T22:32:13.124990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataframe\n",
    "df = pd.read_csv(\"biomedical_sentences.csv\")"
   ],
   "id": "ef8ac6e84b755c8f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:14.540336Z",
     "start_time": "2025-04-01T22:32:13.327198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the Pythia model and the tokenizer\n",
    "model = Pythia_model(\"EleutherAI/pythia-70m-deduped\", \"EleutherAI/pythia-70m-deduped\")"
   ],
   "id": "216a06634e9ab003",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `GPTNeoXSdpaAttention` class is deprecated in favor of simply modifying the `config._attn_implementation`attribute of the `GPTNeoXAttention` class! It will be removed in v4.48\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:14.546574Z",
     "start_time": "2025-04-01T22:32:14.544921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# activations_of_interest = []\n",
    "# for i in range(len(df)):\n",
    "#     activations_of_interest.append(model.get_activation_for_token(df.iloc[i]['Sentence'], df.iloc[i]['Term']))"
   ],
   "id": "aa6475a7eb4ba653",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:14.589847Z",
     "start_time": "2025-04-01T22:32:14.587821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# with open('final_layer_activations.pkl', 'wb') as f:\n",
    "#     pickle.dump(activations_of_interest, f)"
   ],
   "id": "839887a3d51ecce",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:14.638092Z",
     "start_time": "2025-04-01T22:32:14.635314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Load the final layer activations\n",
    "# with open('final_layer_activations.pkl', 'rb') as f:\n",
    "#     activations_of_interest = pickle.load(f) #final_layer_activations"
   ],
   "id": "a862521321638fdb",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:14.684636Z",
     "start_time": "2025-04-01T22:32:14.681906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Get the activations without any None values\n",
    "# non_none_activations = [i for i in activations_of_interest if i is not None]"
   ],
   "id": "c3e654a7095a1d67",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:14.733130Z",
     "start_time": "2025-04-01T22:32:14.729910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # None values are handled implicitly\n",
    "# k_means = k_means.k_means(non_none_activations, 4, distance_metric = \"Euclidean\")\n",
    "# # Save the k_means model\n",
    "# # k_means.save(\"mesh_k_means\")"
   ],
   "id": "a3e49c5310b8d612",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:14.782056Z",
     "start_time": "2025-04-01T22:32:14.779473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # SAve the k_means model\n",
    "# joblib.dump(k_means, \"mesh_k_means\")"
   ],
   "id": "ead6a20c821c8fba",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:14.831376Z",
     "start_time": "2025-04-01T22:32:14.827788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Load the k_means model\n",
    "# k_means = joblib.load(\"mesh_k_means\")"
   ],
   "id": "e5c3b590a9b232c8",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:14.879863Z",
     "start_time": "2025-04-01T22:32:14.876610Z"
    }
   },
   "cell_type": "code",
   "source": "# preds = k_means.predict(non_none_activations)",
   "id": "867fbd69b70bd1db",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:14.928001Z",
     "start_time": "2025-04-01T22:32:14.924561Z"
    }
   },
   "cell_type": "code",
   "source": "# print(preds)",
   "id": "777ffe33b4960487",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:14.974917Z",
     "start_time": "2025-04-01T22:32:14.972334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Visualize and validate the hypothesis.\n",
    "# # Find out which activation belongs to which cluster and keyword.\n",
    "# # Create a list of size all_terms\n",
    "# common_keywords = [[] for i in range(len(all_terms))]\n",
    "# count = 0\n",
    "# for i in range(len(activations_of_interest)):\n",
    "#     if activations_of_interest[i] is not None:\n",
    "#         # Find whihch all term it belongs to\n",
    "#         for j in range(len(all_terms)):\n",
    "#             if all_terms[j].lower() in df.iloc[i]['Sentence'].lower():\n",
    "#                 common_keywords[j].append(preds[count])\n",
    "#                 count += 1\n",
    "#                 break\n"
   ],
   "id": "277fb4ad62794f9e",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:15.022013Z",
     "start_time": "2025-04-01T22:32:15.019182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(common_keywords[6])\n",
    "# print(all_terms[6])"
   ],
   "id": "f280745da6b3a4f3",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:15.068942Z",
     "start_time": "2025-04-01T22:32:15.066323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Find the cluster wise means, and print them. I wanna see something.\n",
    "# for i in range(len(common_keywords)):\n",
    "#     print(all_terms[i], np.mean(common_keywords[i]))"
   ],
   "id": "3efd4c5349b97b91",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:32:15.530139Z",
     "start_time": "2025-04-01T22:32:15.115635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sparse_activations_of_interest = []\n",
    "for i in range(len(df)):\n",
    "     sparse_activations_of_interest.append(model.get_sparse_activations_for_token(df.iloc[i]['Sentence'], df.iloc[i]['Term']))"
   ],
   "id": "2dc10e119d88b9e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activations device cuda:0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AutoEncoder' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m sparse_activations_of_interest \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(df)):\n\u001B[0;32m----> 3\u001B[0m      sparse_activations_of_interest\u001B[38;5;241m.\u001B[39mappend(\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_sparse_activations_for_token\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mSentence\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTerm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/dictionary_learning/clustering.py:82\u001B[0m, in \u001B[0;36mPythia_model.get_sparse_activations_for_token\u001B[0;34m(self, sentence, keyword)\u001B[0m\n\u001B[1;32m     80\u001B[0m activations \u001B[38;5;241m=\u001B[39m activations\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     81\u001B[0m \u001B[38;5;66;03m# Initialize the sparse autoencoder model for the final layer.\u001B[39;00m\n\u001B[0;32m---> 82\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSAE device\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msae\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m)\n\u001B[1;32m     83\u001B[0m sparse_acts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msae\u001B[38;5;241m.\u001B[39mencode(activations)\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sparse_acts\n",
      "File \u001B[0;32m~/dictionary_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1928\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1926\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[1;32m   1927\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[0;32m-> 1928\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[1;32m   1929\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1930\u001B[0m )\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'AutoEncoder' object has no attribute 'device'"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save the sparse activations\n",
    "with open('sparse_activations.pkl', 'wb') as f:\n",
    "    pickle.dump(sparse_activations_of_interest, f)"
   ],
   "id": "7f8247c40728b973"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "I think this is a good starting point that we can iterate upon later.\n",
    "\n",
    "Some things that I can think of:-\n",
    "1. Add more sentences to the dataset.\n",
    "2. Bigger models\n",
    "3. Different distance metrics ( Cosine similarity / KL divergence )\n",
    "4. Other clustering algorithms"
   ],
   "id": "99a39688e6a1822e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aa6f803459f1c65c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
